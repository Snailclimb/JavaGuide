---
title: Summary of common Java concurrency interview questions (Part 2)
category: Java
tag:
  - Java concurrency
head:
  - - meta
    - name: keywords
      content: multi-threading, deadlock, thread pool, CAS, AQS
  - - meta
    - name: description
      content: Summary of common Java concurrency knowledge points and interview questions (including detailed answers), I hope it will be helpful to you!
---

<!-- @include: @article-header.snippet.md -->

##ThreadLocal

### What is ThreadLocal used for?

Normally, the variables we create can be accessed and modified by any thread. This can lead to data races and thread safety issues in multi-threaded environments. So, if you want each thread to have its own exclusive local variable, how to implement it? **

The `ThreadLocal` class provided in the JDK is designed to solve this problem. **The `ThreadLocal` class allows each thread to bind its own value**, which can be vividly compared to a "box that stores data". Each thread has its own independent box for storing private data to ensure that data between different threads do not interfere with each other.

When you create a `ThreadLocal` variable, each thread that accesses the variable will have an independent copy. This is where the name `ThreadLocal` comes from. A thread can obtain a local copy of its own thread through the `get()` method, or modify the value of the copy through the `set()` method, thereby avoiding thread safety issues.

To give a simple example: Suppose two people go to the treasure house to collect treasures. If they share a bag, there will inevitably be arguments; but if everyone has an independent bag, there will be no such problem. If these two people are compared to threads, then `ThreadLocal` is a method used to prevent these two threads from competing for the same resource.

```java
public class ThreadLocalExample {
    private static ThreadLocal<Integer> threadLocal = ThreadLocal.withInitial(() -> 0);

    public static void main(String[] args) {
        Runnable task = () -> {
            int value = threadLocal.get();
            value += 1;
            threadLocal.set(value);
            System.out.println(Thread.currentThread().getName() + " Value: " + threadLocal.get());
        };

        Thread thread1 = new Thread(task, "Thread-1");
        Thread thread2 = new Thread(task, "Thread-2");

        thread1.start(); // Output: Thread-1 Value: 1
        thread2.start(); // Output: Thread-2 Value: 1
    }
}
```

### ‚≠êÔ∏èDo you understand the principle of ThreadLocal?

Start with the `Thread` class source code.

```java
public class Thread implements Runnable {
    //......
    //ThreadLocal value related to this thread. Maintained by ThreadLocal class
    ThreadLocal.ThreadLocalMap threadLocals = null;

    //InheritableThreadLocal value related to this thread. Maintained by InheritableThreadLocal class
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
    //......
}
```

From the source code of the `Thread` class above, we can see that there is a `threadLocals` and an `inheritableThreadLocals` variable in the `Thread` class. They are both variables of the `ThreadLocalMap` type. We can understand `ThreadLocalMap` as a customized `HashMap` implemented by the `ThreadLocal` class. By default, these two variables are null. They are created only when the current thread calls the `set` or `get` method of the `ThreadLocal` class. In fact, when calling these two methods, we call the `get()` and `set()` methods corresponding to the `ThreadLocalMap` class.

`set()` method of `ThreadLocal` class

```java
public void set(T value) {
    //Get the thread of the current request
    Thread t = Thread.currentThread();
    //Get the threadLocals variable (hash table structure) inside the Thread class
    ThreadLocalMap map = getMap(t);
    if (map != null)
        //Put the value to be stored into this hash table
        map.set(this, value);
    else
        createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}
```

Through the above content, we can conclude by guessing: **The final variable is placed in the `ThreadLocalMap` of the current thread, and does not exist on `ThreadLocal`. `ThreadLocal` can be understood as just a package of `ThreadLocalMap`, passing the variable value. ** In the `ThrealLocal` class, after you can obtain the current thread object through `Thread.currentThread()`, you can directly access the `ThreadLocalMap` object of the thread through `getMap(Thread t)`.

**Each `Thread` has a `ThreadLocalMap`, and `ThreadLocalMap` can store key-value pairs with `ThreadLocal` as the key and the Object object as the value. **

```java
ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {
    //......
}
```

For example, if we declare two `ThreadLocal` objects in the same thread, `Thread` internally uses the only `ThreadLocal` to store data. The key of `ThreadLocalMap` is the `ThreadLocal` object, and the value is the value set by calling the `set` method of the `ThreadLocal` object.

The `ThreadLocal` data structure is shown in the figure below:

![ThreadLocal data structure](https://oss.javaguide.cn/github/javaguide/java/concurrent/threadlocal-data-structure.png)

`ThreadLocalMap` is a static inner class of `ThreadLocal`.

![ThreadLocal inner class](https://oss.javaguide.cn/github/javaguide/java/concurrent/thread-local-inner-class.png)

### ‚≠êÔ∏èWhat causes ThreadLocal memory leak problem?

The root cause of `ThreadLocal` memory leaks lies in its internal implementation mechanism.

From the above content, we already know: each thread maintains a map named `ThreadLocalMap`. When you use `ThreadLocal` to store a value, you are actually storing the value in the current thread's `ThreadLocalMap`, with the `ThreadLocal` instance itself as the key and the value you want to store as the value.

The source code of `set()` method of `ThreadLocal` is as follows:

```java
public void set(T value) {
    Thread t = Thread.currentThread(); // Get the current thread
    ThreadLocalMap map = getMap(t); // Get the ThreadLocalMap of the current thread
    if (map != null) {
        map.set(this, value); // Set value
    } else {
        createMap(t, value); // Create a new ThreadLocalMap
    }
}
```In the `set()` and `createMap()` methods of `ThreadLocalMap`, the `ThreadLocal` object itself is not directly stored. Instead, the hash value of `ThreadLocal` is used to calculate the array index, and is finally stored in an array of type `static class Entry extends WeakReference<ThreadLocal<?>>`.

```java
int i = key.threadLocalHashCode & (len-1);
```

`Entry` of `ThreadLocalMap` is defined as follows:

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
    Object value;

    Entry(ThreadLocal<?> k, Object v) {
        super(k);
        value = v;
    }
}
```

`ThreadLocalMap`‚Äôs `key` and `value` reference mechanism:

- **key is a weak reference**: The key in `ThreadLocalMap` is a weak reference to `ThreadLocal` (`WeakReference<ThreadLocal<?>>`). This means that if a `ThreadLocal` instance is no longer pointed to by any strong reference, the garbage collector will recycle the instance during the next GC, causing the corresponding key in `ThreadLocalMap` to become `null`.
- **value is a strong reference**: Even if `key` is recycled by GC, `value` is still strongly referenced by `ThreadLocalMap.Entry` and cannot be recycled by GC.

When a `ThreadLocal` instance loses its strong reference, its corresponding value still exists in `ThreadLocalMap` because the `Entry` object has a strong reference to it. If the thread continues to survive (such as a thread in a thread pool), `ThreadLocalMap` will always exist, causing the entry with key `null` to not be garbage collected, which will cause a memory leak.

In other words, for a memory leak to occur, two conditions need to be met at the same time:

1. The `ThreadLocal` instance is no longer strongly referenced;
2. The thread continues to survive, causing `ThreadLocalMap` to exist for a long time.

Although `ThreadLocalMap` will try to clean up entries with null keys during `get()`, `set()` and `remove()` operations, this cleaning mechanism is passive and not completely reliable.

**How ‚Äã‚Äãto avoid memory leaks? **

1. After using `ThreadLocal`, be sure to call the `remove()` method. This is the safest and most recommended approach. The `remove()` method will explicitly remove the corresponding entry from `ThreadLocalMap`, completely eliminating the risk of memory leaks. Even if `ThreadLocal` is defined as `static final`, it is strongly recommended to call `remove()` after each use.
2. In thread pool and other thread reuse scenarios, using the `try-finally` block can ensure that the `remove()` method will be executed even if an exception occurs.

### ‚≠êÔ∏èHow to pass the value of ThreadLocal across threads?

Because the variable value of `ThreadLocal` is stored in `Thread`, and the parent and child threads belong to different `Thread`. Therefore, in an asynchronous scenario, the `ThreadLocal` value of the parent and child threads cannot be transferred.

If you want to pass `ThreadLocal` value in asynchronous scenario, there are two solutions:

- `InheritableThreadLocal`: `InheritableThreadLocal` is a tool provided by JDK1.2 and inherits from `ThreadLocal`. When using `InheritableThreadLocal`, when creating a child thread, the child thread will inherit the `ThreadLocal` value in the parent thread, but the `ThreadLocal` value transfer in the thread pool scenario cannot be supported.
- `TransmittableThreadLocal`: `TransmittableThreadLocal` (referred to as TTL) is Alibaba's open source tool class. It inherits and enhances the `InheritableThreadLocal` class and can support `ThreadLocal` value transfer in a thread pool scenario. Project address: <https://github.com/alibaba/transmittable-thread-local>.

#### InheritableThreadLocal principle

`InheritableThreadLocal` implements the function of inheriting the `ThreadLocal` value of the parent thread when creating an asynchronous thread. This class is provided by the JDK team. It implements the transfer of the `ThreadLocal` value when creating a thread by transforming the `Thread` class in the JDK source code package.

**Where is the value of `InheritableThreadLocal` stored? **

A new `ThreadLocalMap` was added to the `Thread` class, named `inheritableThreadLocals`. This variable is used to store `ThreadLocal` values that need to be passed across threads. As follows:

```JAVA
class Thread implements Runnable {
    ThreadLocal.ThreadLocalMap threadLocals = null;
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
}
```

**How to complete the passing of `ThreadLocal` value? **

This is achieved by transforming the constructor of the `Thread` class. When creating a `Thread` thread, just get the `inheritableThreadLocals` variable of the parent thread and assign it to the child thread. The relevant code is as follows:

```JAVA
// The constructor of Thread will call the init() method
private void init(/* ... */) {
	// 1. Get the parent thread
    Thread parent = currentThread();
    // 2. Assign the inheritableThreadLocals of the parent thread to the child thread
    if (inheritThreadLocals && parent.inheritableThreadLocals != null)
        this.inheritableThreadLocals =
        	ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
}
```

#### TransmittableThreadLocal principle

By default, JDK does not support the function of `ThreadLocal` value transfer in thread pool scenarios, so Alibaba open sourced a set of tools `TransmittableThreadLocal` to implement this function.

Alibaba cannot change the source code of the JDK, so it uses the **decorator mode** internally to enhance the original functions to achieve the `ThreadLocal` value transfer in the thread pool scenario.

There are two places where TTL has been transformed:

- Implement a custom `Thread` and perform the assignment operation of the `ThreadLocal` variable inside the `run()` method.

- Decoration based on **Thread Pool**, in the `execute()` method, do not submit the JDK internal `Thread`, but submit the custom `Thread`.

If you want to view the relevant source code, you can introduce Maven dependencies for download.

```XML
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>transmittable-thread-local</artifactId>
    <version>2.12.0</version>
</dependency>
```

#### Application scenarios

1. **Pressure test flow mark**: In the pressure test scenario, use `ThreadLocal` to store the stress test mark, which is used to distinguish the pressure test flow and the real flow. If the tag is missing, the stress test traffic may be mistakenly treated as online traffic.
2. **Context delivery**: In a distributed system, transfer link tracking information (such as Trace ID) or user context information.

## Thread pool

### What is a thread pool?

As the name suggests, a thread pool is a resource pool that manages a series of threads. When there is a task to be processed, the thread is directly obtained from the thread pool for processing. After processing, the thread will not be destroyed immediately, but will wait for the next task.

### ‚≠êÔ∏èWhy use thread pool?

Pooling technology must be familiar to everyone. Thread pools, database connection pools, HTTP connection pools, etc. are all applications of this idea. The idea of ‚Äã‚Äãpooling technology is mainly to reduce the consumption of resources each time and improve the utilization of resources.

Thread pools provide a way to limit and manage resources, including executing a task. Each thread pool also maintains some basic statistics, such as the number of completed tasks. Using a thread pool mainly brings the following benefits:

1. **Reduce resource consumption**: Threads in the thread pool can be reused. Once a thread completes a task, it is not destroyed immediately, but returns to the pool to wait for the next task. This avoids the overhead caused by frequently creating and destroying threads.2. **Improve response speed**: Because the thread pool usually maintains a certain number of core threads (or "resident workers"), when tasks come, they can be directly handed over to these existing and idle threads for execution, saving the time of creating threads, and tasks can be processed faster.
3. **Improve thread manageability**: The thread pool allows us to uniformly manage the threads in the pool. We can configure the size of the thread pool (number of core threads, maximum number of threads), type and size of task queue, rejection policy, etc. This can control the total number of concurrent threads, prevent resource exhaustion, and ensure system stability. At the same time, the thread pool usually also provides a monitoring interface to facilitate us to understand the running status of the thread pool (such as how many active threads there are, how many tasks are queued, etc.) and to facilitate tuning.

### How to create a thread pool?

In Java, there are two main ways to create a thread pool:

**Method 1: Create directly through the `ThreadPoolExecutor` constructor (recommended)**

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/threadpoolexecutor-construtors.png)

This is the most recommended method because it allows developers to explicitly specify the core parameters of the thread pool and have more granular control over the running behavior of the thread pool, thus avoiding the risk of resource exhaustion.

**Method 2: Create through `Executors` tool class (not recommended for production environment)**

The method of creating a thread pool provided by the `Executors` tool class is shown in the figure below:

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/executors-new-thread-pool-methods.png)

It can be seen that multiple types of thread pools can be created through the `Executors` tool class, including:

- `FixedThreadPool`: A thread pool with a fixed number of threads. The number of threads in this thread pool always remains the same. When a new task is submitted, if there are idle threads in the thread pool, it will be executed immediately. If not, the new task will be temporarily stored in a task queue, and when a thread is idle, the task in the task queue will be processed.
- `SingleThreadExecutor`: Thread pool with only one thread. If more than one task is submitted to the thread pool, the task will be saved in a task queue. When the thread is idle, the tasks in the queue will be executed in first-in, first-out order.
- `CachedThreadPool`: A thread pool that can adjust the number of threads according to actual conditions. The number of threads in the thread pool is uncertain, but if there are idle threads that can be reused, the reusable threads will be used first. If all threads are working and a new task is submitted, a new thread will be created to handle the task. After all threads complete the execution of the current task, they will be returned to the thread pool for reuse.
- `ScheduledThreadPool`: A thread pool that runs tasks after a given delay or executes tasks periodically.

### ‚≠êÔ∏èWhy is it not recommended to use the built-in thread pool?

In the "Concurrency Processing" chapter of the "Alibaba Java Development Manual", it is clearly stated that thread resources must be provided through the thread pool, and explicit creation of threads in the application is not allowed.

**Why? **

> The advantage of using a thread pool is to reduce the time spent on creating and destroying threads and system resource overhead, and solve the problem of insufficient resources. If the thread pool is not used, it may cause the system to create a large number of similar threads, leading to memory consumption or "excessive switching" problems.

In addition, the mandatory thread pool in the "Alibaba Java Development Manual" does not allow the use of `Executors` to create, but through the `ThreadPoolExecutor` constructor. This processing method allows the writing students to be more clear about the operating rules of the thread pool and avoid the risk of resource exhaustion.

The disadvantages of `Executors` returning thread pool objects are as follows (will be introduced in detail later):

- `FixedThreadPool` and `SingleThreadExecutor`: use the blocking queue `LinkedBlockingQueue`. The maximum length of the task queue is `Integer.MAX_VALUE`, which can be regarded as unbounded and may accumulate a large number of requests, resulting in OOM.
- `CachedThreadPool`: uses a synchronized queue `SynchronousQueue`, and the number of threads allowed to be created is `Integer.MAX_VALUE`. If there are too many tasks and the execution speed is slow, a large number of threads may be created, resulting in OOM.
- `ScheduledThreadPool` and `SingleThreadScheduledExecutor`: use the unbounded delay blocking queue `DelayedWorkQueue`, the maximum length of the task queue is `Integer.MAX_VALUE`, which may accumulate a large number of requests, resulting in OOM.

```java
public static ExecutorService newFixedThreadPool(int nThreads) {
    // The default length of LinkedBlockingQueue is Integer.MAX_VALUE, which can be regarded as unbounded
    return new ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>());

}

public static ExecutorService newSingleThreadExecutor() {
    // The default length of LinkedBlockingQueue is Integer.MAX_VALUE, which can be regarded as unbounded
    return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>()));

}

// Synchronous queue SynchronousQueue, no capacity, the maximum number of threads is Integer.MAX_VALUE`
public static ExecutorService newCachedThreadPool() {

    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,60L, TimeUnit.SECONDS,new SynchronousQueue<Runnable>());

}

// DelayedWorkQueue (delayed blocking queue)
public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    return new ScheduledThreadPoolExecutor(corePoolSize);
}
public ScheduledThreadPoolExecutor(int corePoolSize) {
    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
          new DelayedWorkQueue());
}
```

### ‚≠êÔ∏èWhat are the common parameters of thread pool? How to explain?

```java
    /**
     * Create a new ThreadPoolExecutor with the given initial parameters.
     */
    public ThreadPoolExecutor(int corePoolSize,//The number of core threads in the thread pool
                              int maximumPoolSize,//The maximum number of threads in the thread pool
                              long keepAliveTime,//When the number of threads is greater than the number of core threads, the maximum time for the excess idle threads to survive
                              TimeUnit unit,//time unit
                              BlockingQueue<Runnable> workQueue,//task queue, used to store queues waiting for execution of tasks
                              ThreadFactory threadFactory,//Thread factory, used to create threads, generally the default is enough
                              RejectedExecutionHandler handler//Rejection strategy, when too many tasks are submitted and cannot be processed in time, we can customize the strategy to handle the tasks
                               ) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }```

`ThreadPoolExecutor` 3 most important parameters:

- `corePoolSize`: When the task queue does not reach the queue capacity, the maximum number of threads that can run simultaneously.
- `maximumPoolSize`: When the tasks stored in the task queue reach the queue capacity, the number of threads that can currently run simultaneously becomes the maximum number of threads.
- `workQueue`: When a new task comes, it will first determine whether the number of currently running threads reaches the number of core threads. If so, the new task will be stored in the queue.

`ThreadPoolExecutor`Other common parameters:

- `keepAliveTime`: When the number of threads in the thread pool is greater than `corePoolSize`, that is, when there are non-core threads (threads other than core threads in the thread pool), these non-core threads will not be destroyed immediately after becoming idle, but will wait until the waiting time exceeds `keepAliveTime` before they will be recycled and destroyed.
- `unit` : The time unit of the `keepAliveTime` parameter.
- `threadFactory` :executor is used when creating a new thread.
- `handler`: rejection strategy (will be introduced in detail later).

The picture below can deepen your understanding of the relationship between various parameters in the thread pool (picture source: "Java Performance Tuning Practice"):

![Relationship between thread pool parameters](https://oss.javaguide.cn/github/javaguide/java/concurrent/relationship-between-thread-pool-parameters.png)

### Will the core threads of the thread pool be recycled?

`ThreadPoolExecutor` will not recycle core threads by default, even if they are idle. This is to reduce the overhead of creating threads, because core threads are usually kept active for a long time. However, if the thread pool is used for cyclic use scenarios and the frequency is not high (there is obvious idle time between cycles), you can consider setting the parameter of the `allowCoreThreadTimeOut(boolean value)` method to `true`, so that the idle (time interval is specified by `keepAliveTime`) core threads will be recycled.

```java
public void allowCoreThreadTimeOut(boolean value) {
    // The keepAliveTime of the core thread must be greater than 0 to enable the timeout mechanism
    if (value && keepAliveTime <= 0) {
        throw new IllegalArgumentException("Core threads must have nonzero keep alive times");
    }
    //Set the value of allowCoreThreadTimeOut
    if (value != allowCoreThreadTimeOut) {
        allowCoreThreadTimeOut = value;
        // If the timeout mechanism is enabled, clean up all idle threads, including core threads
        if (value) {
            interruptIdleWorkers();
        }
    }
}
```

### What state is the core thread in when it is idle?

When the core thread is idle, its status is divided into the following two situations:

- **Set the survival time of the core thread**: When the core thread is idle, it will be in the `WAITING` state, waiting to obtain tasks. If the blocking waiting time exceeds the core thread survival time, the thread will exit the work, the thread will be removed from the worker thread collection of the thread pool, and the thread status will change to `TERMINATED` state.
- **The survival time of the core thread is not set**: When the core thread is idle, it will always be in the `WAITING` state, waiting to obtain tasks, and the core thread will always survive in the thread pool.

When there are available tasks in the queue, the blocked thread will be awakened, and the thread's state will change from `WAITING` state to `RUNNABLE` state, and then the corresponding task will be executed.

Next, learn about how the thread pool is done internally through the relevant source code.

Threads are abstracted into `Worker` inside the thread pool. When `Worker` is started, it will continue to obtain tasks from the task queue.

When acquiring tasks, the behavior of acquiring tasks from the task queue (`BlockingQueue`) will be determined based on the `timed` value.

If "the survival time of the core thread is set" or "the number of threads exceeds the number of core threads", then `timed` is marked as `true`, indicating that `poll()` needs to be used to specify the timeout when acquiring the task.

- `timed == true`: Use `poll(timeout, unit)` to get the task. If you use the `poll(timeout, unit)` method to obtain the task timeout, the current thread will exit execution (`TERMINATED`) and the thread will be removed from the thread pool.
- `timed == false`: Use `take()` to get the task. Using the `take()` method to obtain a task will cause the current thread to be blocked and waiting (`WAITING`).

The source code is as follows:

```JAVA
// ThreadPoolExecutor
private Runnable getTask() {
    boolean timedOut = false;
    for (;;) {
        // ...

        // 1. If "the survival time of the core thread is set" or "the number of threads exceeds the number of core threads", then timed is true.
        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;
        // 2. Decrease the number of threads.
        // wc > maximuimPoolSize: The number of threads in the thread pool exceeds the maximum number of threads. Where wc is the number of threads in the thread pool.
        // timed && timeOut: timeOut indicates that the acquisition task has timed out.
        // Divided into two situations: the core thread has set a survival time && if the acquisition task times out, the number of threads will be deducted; the number of threads exceeds the number of core threads && if the acquisition task times out, the number of threads will be deducted.
        if ((wc > maximumPoolSize || (timed && timedOut))
            && (wc > 1 || workQueue.isEmpty())) {
            if (compareAndDecrementWorkerCount(c))
                return null;
            continue;
        }
        try {
            // 3. If timed is true, use poll() to obtain the task; otherwise, use take() to obtain the task.
            Runnable r = timed?
                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS):
                workQueue.take();
            // 4. Return after obtaining the task.
            if (r != null)
                return r;
            timedOut = true;
        } catch (InterruptedException retry) {
            timedOut = false;
        }
    }
}
```

### ‚≠êÔ∏èWhat are the rejection strategies of the thread pool?

If the number of threads currently running simultaneously reaches the maximum number of threads and the queue is full of tasks, `ThreadPoolExecutor` defines some strategies:

- `ThreadPoolExecutor.AbortPolicy`: Throws `RejectedExecutionException` to reject the processing of new tasks.
- `ThreadPoolExecutor.CallerRunsPolicy`: Call the executor's own thread to run the task, that is, run (`run`) the rejected task directly in the thread that calls the `execute` method. If the executor has been closed, the task will be discarded. Therefore, this strategy will reduce the speed of new task submission and affect the overall performance of the program. You can choose this strategy if your application can tolerate this delay and you require that every task request must be executed.
- `ThreadPoolExecutor.DiscardPolicy`: New tasks are not processed and discarded directly.
- `ThreadPoolExecutor.DiscardOldestPolicy`: This policy will discard the oldest unhandled task request.For example: When Spring creates a thread pool through `ThreadPoolTaskExecutor` or we directly use the constructor of `ThreadPoolExecutor`, when we do not specify the `RejectedExecutionHandler` rejection policy to configure the thread pool, the default is `AbortPolicy`. Under this rejection strategy, if the queue is full, `ThreadPoolExecutor` will throw a `RejectedExecutionException` exception to reject the incoming task, which means that you will lose the processing of this task. If you don't want to discard tasks, you can use `CallerRunsPolicy`. `CallerRunsPolicy` is different from several other policies in that it neither abandons the task nor throws an exception. Instead, it returns the task to the caller and uses the caller's thread to execute the task.

```java
public static class CallerRunsPolicy implements RejectedExecutionHandler {

        public CallerRunsPolicy() { }

        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                // Directly execute the main thread instead of thread execution in the thread pool
                r.run();
            }
        }
    }
```

### If dropping tasks is not allowed, which rejection policy should be chosen?

Based on the above introduction to the thread pool rejection policy, I believe everyone can easily come to the answer: `CallerRunsPolicy`.

Here we will take a look at the source code of `CallerRunsPolicy`:

```java
public static class CallerRunsPolicy implements RejectedExecutionHandler {

        public CallerRunsPolicy() { }


        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            //As long as the current program is not closed, use the thread that executes the execute method to perform the task.
            if (!e.isShutdown()) {

                r.run();
            }
        }
    }
```

It can be seen from the source code that as long as the current program is not closed, the thread that executes the `execute` method will be used to perform the task.

### What are the risks of the CallerRunsPolicy deny policy? How to solve it?

We also mentioned above: If you want to ensure that any task request will be executed, it is more appropriate to choose the `CallerRunsPolicy` rejection policy.

However, if the task of reaching `CallerRunsPolicy` is a very time-consuming task, and the thread that handles the submitted task is the main thread, it may cause the main thread to be blocked and affect the normal operation of the program.

Here is a simple example. The thread pool limits the maximum number of threads to 2 and the blocking queue size to 1 (which means that the fourth task will reach the rejection policy). `ThreadUtil` is a tool class provided by Hutool:

```java
public class ThreadPoolTest {

    private static final Logger log = LoggerFactory.getLogger(ThreadPoolTest.class);

    public static void main(String[] args) {
        //Create a thread pool with the number of core threads being 1 and the maximum number of threads being 2
        // When the number of threads is greater than the number of core threads, the maximum time that the excess idle threads can survive is 60 seconds.
        // The task queue is an ArrayBlockingQueue with a capacity of 1, and the saturation policy is CallerRunsPolicy.
        ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1,
                2,
                60,
                TimeUnit.SECONDS,
                new ArrayBlockingQueue<>(1),
                new ThreadPoolExecutor.CallerRunsPolicy());

        // Submit the first task to be executed by the core thread
        threadPoolExecutor.execute(() -> {
            log.info("Core thread executes the first task");
            ThreadUtil.sleep(1, TimeUnit.MINUTES);
        });

        //Submit the second task. Since the core thread is occupied, the task will enter the queue and wait.
        threadPoolExecutor.execute(() -> {
            log.info("Non-core thread processes the second task enqueued");
            ThreadUtil.sleep(1, TimeUnit.MINUTES);
        });

        //Submit the third task. Since the core thread is occupied and the queue is full, a non-core thread is created for processing.
        threadPoolExecutor.execute(() -> {
            log.info("Non-core thread processing third task");
            ThreadUtil.sleep(1, TimeUnit.MINUTES);
        });

        //Submit the fourth task. Since both core threads and non-core threads are occupied and the queue is full, according to the CallerRunsPolicy policy, the task will be executed by the thread that submitted the task (i.e. the main thread).
        threadPoolExecutor.execute(() -> {
            log.info("The main thread processes the fourth task");
            ThreadUtil.sleep(2, TimeUnit.MINUTES);
        });

        //Submit the fifth task. The main thread is stuck by the fourth task. The task must wait until the main thread finishes executing before it can be submitted.
        threadPoolExecutor.execute(() -> {
            log.info("Core thread executes fifth task");
        });

        // Close the thread pool
        threadPoolExecutor.shutdown();
    }
}

```

Output:

```bash
18:19:48.203 INFO [pool-1-thread-1] c.j.concurrent.ThreadPoolTest - The core thread executes the first task
18:19:48.203 INFO [pool-1-thread-2] c.j.concurrent.ThreadPoolTest - Non-core thread processing third task
18:19:48.203 INFO [main] c.j.concurrent.ThreadPoolTest - The main thread processes the fourth task
18:20:48.212 INFO [pool-1-thread-2] c.j.concurrent.ThreadPoolTest - Non-core thread handles second enqueued task
18:21:48.219 INFO [pool-1-thread-2] c.j.concurrent.ThreadPoolTest - The core thread executes the fifth task
```

It can be seen from the output results that because of the rejection policy of `CallerRunsPolicy`, time-consuming tasks are executed on the main thread, causing the thread pool to be blocked, which in turn causes subsequent tasks to be unable to be executed in time, and in serious cases may lead to OOM.

Let's start with the essence of the problem. The caller uses `CallerRunsPolicy` in the hope that all tasks can be executed, and tasks that cannot be processed temporarily are stored in the blocking queue `BlockingQueue`. In this case, if memory permits, we can increase the size of the blocking queue `BlockingQueue` and adjust the heap memory to accommodate more tasks to ensure that tasks can be executed accurately.

In order to make full use of the CPU, we can also adjust the `maximumPoolSize` (maximum number of threads) parameter of the thread pool, which can increase the task processing speed and avoid running out of memory due to too many tasks accumulated in the `BlockingQueue`.

![Adjust the blocking queue size and maximum number of threads](https://oss.javaguide.cn/github/javaguide/java/concurrent/threadpool-reject-2-threadpool-reject-01.png)Â¶ÇÊûúÊúçÂä°Âô®ËµÑÊ∫ê‰ª•ËææÂà∞ÂèØÂà©Áî®ÁöÑÊûÅÈôêÔºåËøôÂ∞±ÊÑèÂë≥Êàë‰ª¨Ë¶ÅÂú®ËÆæËÆ°Á≠ñÁï•‰∏äÊîπÂèòÁ∫øÁ®ãÊ±†ÁöÑË∞ÉÂ∫¶‰∫ÜÔºåÊàë‰ª¨ÈÉΩÁü•ÈÅìÔºåÂØºËá¥‰∏ªÁ∫øÁ®ãÂç°Ê≠ªÁöÑÊú¨Ë¥®Â∞±ÊòØÂõ†‰∏∫Êàë‰ª¨‰∏çÂ∏åÊúõ‰ªª‰Ωï‰∏Ä‰∏™‰ªªÂä°Ë¢´‰∏¢ÂºÉ„ÄÇÊç¢‰∏™ÊÄùË∑ØÔºåÊúâÊ≤°ÊúâÂäûÊ≥ïÊó¢ËÉΩ‰øùËØÅ‰ªªÂä°‰∏çË¢´‰∏¢ÂºÉ‰∏îÂú®ÊúçÂä°Âô®Êúâ‰ΩôÂäõÊó∂ÂèäÊó∂Â§ÑÁêÜÂë¢Ôºü

ËøôÈáåÊèê‰æõÁöÑ‰∏ÄÁßç**‰ªªÂä°ÊåÅ‰πÖÂåñ**ÁöÑÊÄùË∑ØÔºåËøôÈáåÊâÄË∞ìÁöÑ‰ªªÂä°ÊåÅ‰πÖÂåñÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫é:

1. ËÆæËÆ°‰∏ÄÂº†‰ªªÂä°Ë°®Â∞Ü‰ªªÂä°Â≠òÂÇ®Âà∞ MySQL Êï∞ÊçÆÂ∫ì‰∏≠„ÄÇ
2. Redis ÁºìÂ≠ò‰ªªÂä°„ÄÇ
3. Â∞Ü‰ªªÂä°Êèê‰∫§Âà∞Ê∂àÊÅØÈòüÂàó‰∏≠„ÄÇ

ËøôÈáå‰ª•ÊñπÊ°à‰∏Ä‰∏∫‰æãÔºåÁÆÄÂçï‰ªãÁªç‰∏Ä‰∏ãÂÆûÁé∞ÈÄªËæëÔºö

1. ÂÆûÁé∞`RejectedExecutionHandler`Êé•Âè£Ëá™ÂÆö‰πâÊãíÁªùÁ≠ñÁï•ÔºåËá™ÂÆö‰πâÊãíÁªùÁ≠ñÁï•Ë¥üË¥£Â∞ÜÁ∫øÁ®ãÊ±†ÊöÇÊó∂Êó†Ê≥ïÂ§ÑÁêÜÔºàÊ≠§Êó∂ÈòªÂ°ûÈòüÂàóÂ∑≤Êª°ÔºâÁöÑ‰ªªÂä°ÂÖ•Â∫ìÔºà‰øùÂ≠òÂà∞ MySQL ‰∏≠Ôºâ„ÄÇÊ≥®ÊÑèÔºöÁ∫øÁ®ãÊ±†ÊöÇÊó∂Êó†Ê≥ïÂ§ÑÁêÜÁöÑ‰ªªÂä°‰ºöÂÖàË¢´ÊîæÂú®ÈòªÂ°ûÈòüÂàó‰∏≠ÔºåÈòªÂ°ûÈòüÂàóÊª°‰∫ÜÊâç‰ºöËß¶ÂèëÊãíÁªùÁ≠ñÁï•„ÄÇ
2. ÁªßÊâø`BlockingQueue`ÂÆûÁé∞‰∏Ä‰∏™Ê∑∑ÂêàÂºèÈòªÂ°ûÈòüÂàóÔºåËØ•ÈòüÂàóÂåÖÂê´ JDK Ëá™Â∏¶ÁöÑ`ArrayBlockingQueue`„ÄÇÂè¶Â§ñÔºåËØ•Ê∑∑ÂêàÂºèÈòªÂ°ûÈòüÂàóÈúÄË¶Å‰øÆÊîπÂèñ‰ªªÂä°Â§ÑÁêÜÁöÑÈÄªËæëÔºå‰πüÂ∞±ÊòØÈáçÂÜô`take()`ÊñπÊ≥ïÔºåÂèñ‰ªªÂä°Êó∂‰ºòÂÖà‰ªéÊï∞ÊçÆÂ∫ì‰∏≠ËØªÂèñÊúÄÊó©ÁöÑ‰ªªÂä°ÔºåÊï∞ÊçÆÂ∫ì‰∏≠Êó†‰ªªÂä°Êó∂ÂÜç‰ªé `ArrayBlockingQueue`‰∏≠ÂéªÂèñ‰ªªÂä°„ÄÇ

![Â∞Ü‰∏ÄÈÉ®ÂàÜ‰ªªÂä°‰øùÂ≠òÂà∞MySQL‰∏≠](https://oss.javaguide.cn/github/javaguide/java/concurrent/threadpool-reject-2-threadpool-reject-02.png)

Êï¥‰∏™ÂÆûÁé∞ÈÄªËæëËøòÊòØÊØîËæÉÁÆÄÂçïÁöÑÔºåÊ†∏ÂøÉÂú®‰∫éËá™ÂÆö‰πâÊãíÁªùÁ≠ñÁï•ÂíåÈòªÂ°ûÈòüÂàó„ÄÇÂ¶ÇÊ≠§‰∏ÄÊù•Ôºå‰∏ÄÊó¶Êàë‰ª¨ÁöÑÁ∫øÁ®ãÊ±†‰∏≠Á∫øÁ®ãËææÂà∞Êª°ËΩΩÊó∂ÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•ÈÄöËøáÊãíÁªùÁ≠ñÁï•Â∞ÜÊúÄÊñ∞‰ªªÂä°ÊåÅ‰πÖÂåñÂà∞ MySQL Êï∞ÊçÆÂ∫ì‰∏≠ÔºåÁ≠âÂà∞Á∫øÁ®ãÊ±†Êúâ‰∫ÜÊúâ‰ΩôÂäõÂ§ÑÁêÜÊâÄÊúâ‰ªªÂä°Êó∂ÔºåËÆ©ÂÖ∂‰ºòÂÖàÂ§ÑÁêÜÊï∞ÊçÆÂ∫ì‰∏≠ÁöÑ‰ªªÂä°‰ª•ÈÅøÂÖç"È••È•ø"ÈóÆÈ¢ò„ÄÇ

ÂΩìÁÑ∂ÔºåÂØπ‰∫éËøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨‰πüÂèØ‰ª•ÂèÇËÄÉÂÖ∂‰ªñ‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂÅöÊ≥ïÔºå‰ª• Netty ‰∏∫‰æãÔºåÂÆÉÁöÑÊãíÁªùÁ≠ñÁï•ÂàôÊòØÁõ¥Êé•ÂàõÂª∫‰∏Ä‰∏™Á∫øÁ®ãÊ±†‰ª•Â§ñÁöÑÁ∫øÁ®ãÂ§ÑÁêÜËøô‰∫õ‰ªªÂä°Ôºå‰∏∫‰∫Ü‰øùËØÅ‰ªªÂä°ÁöÑÂÆûÊó∂Â§ÑÁêÜÔºåËøôÁßçÂÅöÊ≥ïÂèØËÉΩÈúÄË¶ÅËâØÂ•ΩÁöÑÁ°¨‰ª∂ËÆæÂ§á‰∏î‰∏¥Êó∂ÂàõÂª∫ÁöÑÁ∫øÁ®ãÊó†Ê≥ïÂÅöÂà∞ÂáÜÁ°ÆÁöÑÁõëÊéßÔºö

```java
private static final class NewThreadRunsPolicy implements RejectedExecutionHandler {
    NewThreadRunsPolicy() {
        super();
    }
    public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
        try {
            //ÂàõÂª∫‰∏Ä‰∏™‰∏¥Êó∂Á∫øÁ®ãÂ§ÑÁêÜ‰ªªÂä°
            final Thread t = new Thread(r, "Temporary task executor");
            t.start();
        } catch (Throwable e) {
            throw new RejectedExecutionException(
                    "Failed to start a new thread", e);
        }
    }
}
```

ActiveMQ ÂàôÊòØÂ∞ùËØïÂú®ÊåáÂÆöÁöÑÊó∂ÊïàÂÜÖÂ∞ΩÂèØËÉΩÁöÑ‰∫âÂèñÂ∞Ü‰ªªÂä°ÂÖ•ÈòüÔºå‰ª•‰øùËØÅÊúÄÂ§ß‰∫§‰ªòÔºö

```java
new RejectedExecutionHandler() {
                @Override
                public void rejectedExecution(final Runnable r, final ThreadPoolExecutor executor) {
                    try {
                        //ÈôêÊó∂ÈòªÂ°ûÁ≠âÂæÖÔºåÂÆûÁé∞Â∞ΩÂèØËÉΩ‰∫§‰ªò
                        executor.getQueue().offer(r, 60, TimeUnit.SECONDS);
                    } catch (InterruptedException e) {
                        throw new RejectedExecutionException("Interrupted waiting for BrokerService.worker");
                    }
                    throw new RejectedExecutionException("Timed Out while attempting to enqueue Task.");
                }
            });
```

### Á∫øÁ®ãÊ±†Â∏∏Áî®ÁöÑÈòªÂ°ûÈòüÂàóÊúâÂì™‰∫õÔºü

Êñ∞‰ªªÂä°Êù•ÁöÑÊó∂ÂÄô‰ºöÂÖàÂà§Êñ≠ÂΩìÂâçËøêË°åÁöÑÁ∫øÁ®ãÊï∞ÈáèÊòØÂê¶ËææÂà∞Ê†∏ÂøÉÁ∫øÁ®ãÊï∞ÔºåÂ¶ÇÊûúËææÂà∞ÁöÑËØùÔºåÊñ∞‰ªªÂä°Â∞±‰ºöË¢´Â≠òÊîæÂú®ÈòüÂàó‰∏≠„ÄÇ

‰∏çÂêåÁöÑÁ∫øÁ®ãÊ±†‰ºöÈÄâÁî®‰∏çÂêåÁöÑÈòªÂ°ûÈòüÂàóÔºåÊàë‰ª¨ÂèØ‰ª•ÁªìÂêàÂÜÖÁΩÆÁ∫øÁ®ãÊ±†Êù•ÂàÜÊûê„ÄÇ

- ÂÆπÈáè‰∏∫ `Integer.MAX_VALUE` ÁöÑ `LinkedBlockingQueue`ÔºàÊó†ÁïåÈòªÂ°ûÈòüÂàóÔºâÔºö`FixedThreadPool` Âíå `SingleThreadExecutor` „ÄÇ`FixedThreadPool`ÊúÄÂ§öÂè™ËÉΩÂàõÂª∫Ê†∏ÂøÉÁ∫øÁ®ãÊï∞ÁöÑÁ∫øÁ®ãÔºàÊ†∏ÂøÉÁ∫øÁ®ãÊï∞ÂíåÊúÄÂ§ßÁ∫øÁ®ãÊï∞Áõ∏Á≠âÔºâÔºå`SingleThreadExecutor`Âè™ËÉΩÂàõÂª∫‰∏Ä‰∏™Á∫øÁ®ãÔºàÊ†∏ÂøÉÁ∫øÁ®ãÊï∞ÂíåÊúÄÂ§ßÁ∫øÁ®ãÊï∞ÈÉΩÊòØ 1ÔºâÔºå‰∫åËÄÖÁöÑ‰ªªÂä°ÈòüÂàóÊ∞∏Ëøú‰∏ç‰ºöË¢´ÊîæÊª°„ÄÇ
- `SynchronousQueue`ÔºàÂêåÊ≠•ÈòüÂàóÔºâÔºö`CachedThreadPool` „ÄÇ`SynchronousQueue` Ê≤°ÊúâÂÆπÈáèÔºå‰∏çÂ≠òÂÇ®ÂÖÉÁ¥†ÔºåÁõÆÁöÑÊòØ‰øùËØÅÂØπ‰∫éÊèê‰∫§ÁöÑ‰ªªÂä°ÔºåÂ¶ÇÊûúÊúâÁ©∫Èó≤Á∫øÁ®ãÔºåÂàô‰ΩøÁî®Á©∫Èó≤Á∫øÁ®ãÊù•Â§ÑÁêÜÔºõÂê¶ÂàôÊñ∞Âª∫‰∏Ä‰∏™Á∫øÁ®ãÊù•Â§ÑÁêÜ‰ªªÂä°„ÄÇ‰πüÂ∞±ÊòØËØ¥Ôºå`CachedThreadPool` ÁöÑÊúÄÂ§ßÁ∫øÁ®ãÊï∞ÊòØ `Integer.MAX_VALUE` ÔºåÂèØ‰ª•ÁêÜËß£‰∏∫Á∫øÁ®ãÊï∞ÊòØÂèØ‰ª•Êó†ÈôêÊâ©Â±ïÁöÑÔºåÂèØËÉΩ‰ºöÂàõÂª∫Â§ßÈáèÁ∫øÁ®ãÔºå‰ªéËÄåÂØºËá¥ OOM„ÄÇ
- `DelayedWorkQueue`ÔºàÂª∂ËøüÈòüÂàóÔºâÔºö`ScheduledThreadPool` Âíå `SingleThreadScheduledExecutor` „ÄÇ`DelayedWorkQueue` ÁöÑÂÜÖÈÉ®ÂÖÉÁ¥†Âπ∂‰∏çÊòØÊåâÁÖßÊîæÂÖ•ÁöÑÊó∂Èó¥ÊéíÂ∫èÔºåËÄåÊòØ‰ºöÊåâÁÖßÂª∂ËøüÁöÑÊó∂Èó¥ÈïøÁü≠ÂØπ‰ªªÂä°ËøõË°åÊéíÂ∫èÔºåÂÜÖÈÉ®ÈááÁî®ÁöÑÊòØ‚ÄúÂ†Ü‚ÄùÁöÑÊï∞ÊçÆÁªìÊûÑÔºåÂèØ‰ª•‰øùËØÅÊØèÊ¨°Âá∫ÈòüÁöÑ‰ªªÂä°ÈÉΩÊòØÂΩìÂâçÈòüÂàó‰∏≠ÊâßË°åÊó∂Èó¥ÊúÄÈù†ÂâçÁöÑ„ÄÇ`DelayedWorkQueue` ÊòØ‰∏Ä‰∏™Êó†ÁïåÈòüÂàó„ÄÇÂÖ∂Â∫ïÂ±ÇËôΩÁÑ∂ÊòØÊï∞ÁªÑÔºå‰ΩÜÂΩìÊï∞ÁªÑÂÆπÈáè‰∏çË∂≥Êó∂ÔºåÂÆÉ‰ºöËá™Âä®ËøõË°åÊâ©ÂÆπÔºåÂõ†Ê≠§ÈòüÂàóÊ∞∏Ëøú‰∏ç‰ºöË¢´Â°´Êª°„ÄÇÂΩì‰ªªÂä°‰∏çÊñ≠Êèê‰∫§Êó∂ÔºåÂÆÉ‰ª¨‰ºöÂÖ®ÈÉ®Ë¢´Ê∑ªÂä†Âà∞ÈòüÂàó‰∏≠„ÄÇËøôÊÑèÂë≥ÁùÄÁ∫øÁ®ãÊ±†ÁöÑÁ∫øÁ®ãÊï∞ÈáèÊ∞∏Ëøú‰∏ç‰ºöË∂ÖËøáÂÖ∂Ê†∏ÂøÉÁ∫øÁ®ãÊï∞ÔºåÊúÄÂ§ßÁ∫øÁ®ãÊï∞ÂèÇÊï∞ÂØπ‰∫é‰ΩøÁî®ËØ•ÈòüÂàóÁöÑÁ∫øÁ®ãÊ±†Êù•ËØ¥ÊòØÊó†ÊïàÁöÑ„ÄÇ
- `ArrayBlockingQueue`ÔºàÊúâÁïåÈòªÂ°ûÈòüÂàóÔºâÔºöÂ∫ïÂ±ÇÁî±Êï∞ÁªÑÂÆûÁé∞ÔºåÂÆπÈáè‰∏ÄÊó¶ÂàõÂª∫ÔºåÂ∞±‰∏çËÉΩ‰øÆÊîπ„ÄÇ

### ‚≠êÔ∏èÁ∫øÁ®ãÊ±†Â§ÑÁêÜ‰ªªÂä°ÁöÑÊµÅÁ®ã‰∫ÜËß£ÂêóÔºü

![ÂõæËß£Á∫øÁ®ãÊ±†ÂÆûÁé∞ÂéüÁêÜ](https://oss.javaguide.cn/github/javaguide/java/concurrent/thread-pool-principle.png)

1. Â¶ÇÊûúÂΩìÂâçËøêË°åÁöÑÁ∫øÁ®ãÊï∞Â∞è‰∫éÊ†∏ÂøÉÁ∫øÁ®ãÊï∞ÔºåÈÇ£‰πàÂ∞±‰ºöÊñ∞Âª∫‰∏Ä‰∏™Á∫øÁ®ãÊù•ÊâßË°å‰ªªÂä°„ÄÇ
2. Â¶ÇÊûúÂΩìÂâçËøêË°åÁöÑÁ∫øÁ®ãÊï∞Á≠â‰∫éÊàñÂ§ß‰∫éÊ†∏ÂøÉÁ∫øÁ®ãÊï∞Ôºå‰ΩÜÊòØÂ∞è‰∫éÊúÄÂ§ßÁ∫øÁ®ãÊï∞ÔºåÈÇ£‰πàÂ∞±ÊääËØ•‰ªªÂä°ÊîæÂÖ•Âà∞‰ªªÂä°ÈòüÂàóÈáåÁ≠âÂæÖÊâßË°å„ÄÇ
3. Â¶ÇÊûúÂêë‰ªªÂä°ÈòüÂàóÊäïÊîæ‰ªªÂä°Â§±Ë¥•Ôºà‰ªªÂä°ÈòüÂàóÂ∑≤ÁªèÊª°‰∫ÜÔºâÔºå‰ΩÜÊòØÂΩìÂâçËøêË°åÁöÑÁ∫øÁ®ãÊï∞ÊòØÂ∞è‰∫éÊúÄÂ§ßÁ∫øÁ®ãÊï∞ÁöÑÔºåÂ∞±Êñ∞Âª∫‰∏Ä‰∏™Á∫øÁ®ãÊù•ÊâßË°å‰ªªÂä°„ÄÇ
4. Â¶ÇÊûúÂΩìÂâçËøêË°åÁöÑÁ∫øÁ®ãÊï∞Â∑≤ÁªèÁ≠âÂêå‰∫éÊúÄÂ§ßÁ∫øÁ®ãÊï∞‰∫ÜÔºåÊñ∞Âª∫Á∫øÁ®ãÂ∞Ü‰ºö‰ΩøÂΩìÂâçËøêË°åÁöÑÁ∫øÁ®ãË∂ÖÂá∫ÊúÄÂ§ßÁ∫øÁ®ãÊï∞ÔºåÈÇ£‰πàÂΩìÂâç‰ªªÂä°‰ºöË¢´ÊãíÁªùÔºåÊãíÁªùÁ≠ñÁï•‰ºöË∞ÉÁî®`RejectedExecutionHandler.rejectedExecution()`ÊñπÊ≥ï„ÄÇ

ÂÜçÊèê‰∏Ä‰∏™ÊúâÊÑèÊÄùÁöÑÂ∞èÈóÆÈ¢òÔºö**Á∫øÁ®ãÊ±†Âú®Êèê‰∫§‰ªªÂä°ÂâçÔºåÂèØ‰ª•ÊèêÂâçÂàõÂª∫Á∫øÁ®ãÂêóÔºü**

Á≠îÊ°àÊòØÂèØ‰ª•ÁöÑÔºÅ`ThreadPoolExecutor` Êèê‰æõ‰∫Ü‰∏§‰∏™ÊñπÊ≥ïÂ∏ÆÂä©Êàë‰ª¨Âú®Êèê‰∫§‰ªªÂä°‰πãÂâçÔºåÂÆåÊàêÊ†∏ÂøÉÁ∫øÁ®ãÁöÑÂàõÂª∫Ôºå‰ªéËÄåÂÆûÁé∞Á∫øÁ®ãÊ±†È¢ÑÁÉ≠ÁöÑÊïàÊûúÔºö

- `prestartCoreThread()`:ÂêØÂä®‰∏Ä‰∏™Á∫øÁ®ãÔºåÁ≠âÂæÖ‰ªªÂä°ÔºåÂ¶ÇÊûúÂ∑≤ËææÂà∞Ê†∏ÂøÉÁ∫øÁ®ãÊï∞ÔºåËøô‰∏™ÊñπÊ≥ïËøîÂõû falseÔºåÂê¶ÂàôËøîÂõû trueÔºõ
- `prestartAllCoreThreads()`:ÂêØÂä®ÊâÄÊúâÁöÑÊ†∏ÂøÉÁ∫øÁ®ãÔºåÂπ∂ËøîÂõûÂêØÂä®ÊàêÂäüÁöÑÊ†∏ÂøÉÁ∫øÁ®ãÊï∞„ÄÇ

### ‚≠êÔ∏èÁ∫øÁ®ãÊ±†‰∏≠Á∫øÁ®ãÂºÇÂ∏∏ÂêéÔºåÈîÄÊØÅËøòÊòØÂ§çÁî®Ôºü

Áõ¥Êé•ËØ¥ÁªìËÆ∫ÔºåÈúÄË¶ÅÂàÜ‰∏§ÁßçÊÉÖÂÜµÔºö

- **‰ΩøÁî®`execute()`Êèê‰∫§‰ªªÂä°**ÔºöÂΩì‰ªªÂä°ÈÄöËøá`execute()`Êèê‰∫§Âà∞Á∫øÁ®ãÊ±†Âπ∂Âú®ÊâßË°åËøáÁ®ã‰∏≠ÊäõÂá∫ÂºÇÂ∏∏Êó∂ÔºåÂ¶ÇÊûúËøô‰∏™ÂºÇÂ∏∏Ê≤°ÊúâÂú®‰ªªÂä°ÂÜÖË¢´ÊçïËé∑ÔºåÈÇ£‰πàËØ•ÂºÇÂ∏∏‰ºöÂØºËá¥ÂΩìÂâçÁ∫øÁ®ãÁªàÊ≠¢ÔºåÂπ∂‰∏îÂºÇÂ∏∏‰ºöË¢´ÊâìÂç∞Âà∞ÊéßÂà∂Âè∞ÊàñÊó•ÂøóÊñá‰ª∂‰∏≠„ÄÇÁ∫øÁ®ãÊ±†‰ºöÊ£ÄÊµãÂà∞ËøôÁßçÁ∫øÁ®ãÁªàÊ≠¢ÔºåÂπ∂ÂàõÂª∫‰∏Ä‰∏™Êñ∞Á∫øÁ®ãÊù•ÊõøÊç¢ÂÆÉÔºå‰ªéËÄå‰øùÊåÅÈÖçÁΩÆÁöÑÁ∫øÁ®ãÊï∞‰∏çÂèò„ÄÇ
- **‰ΩøÁî®`submit()`Êèê‰∫§‰ªªÂä°**ÔºöÂØπ‰∫éÈÄöËøá`submit()`Êèê‰∫§ÁöÑ‰ªªÂä°ÔºåÂ¶ÇÊûúÂú®‰ªªÂä°ÊâßË°å‰∏≠ÂèëÁîüÂºÇÂ∏∏ÔºåËøô‰∏™ÂºÇÂ∏∏‰∏ç‰ºöÁõ¥Êé•ÊâìÂç∞Âá∫Êù•„ÄÇÁõ∏ÂèçÔºåÂºÇÂ∏∏‰ºöË¢´Â∞ÅË£ÖÂú®Áî±`submit()`ËøîÂõûÁöÑ`Future`ÂØπË±°‰∏≠„ÄÇÂΩìË∞ÉÁî®`Future.get()`ÊñπÊ≥ïÊó∂ÔºåÂèØ‰ª•ÊçïËé∑Âà∞‰∏Ä‰∏™`ExecutionException`„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÁ∫øÁ®ã‰∏ç‰ºöÂõ†‰∏∫ÂºÇÂ∏∏ËÄåÁªàÊ≠¢ÔºåÂÆÉ‰ºöÁªßÁª≠Â≠òÂú®‰∫éÁ∫øÁ®ãÊ±†‰∏≠ÔºåÂáÜÂ§áÊâßË°åÂêéÁª≠ÁöÑ‰ªªÂä°„ÄÇ

ÁÆÄÂçïÊù•ËØ¥Ôºö‰ΩøÁî®`execute()`Êó∂ÔºåÊú™ÊçïËé∑ÂºÇÂ∏∏ÂØºËá¥Á∫øÁ®ãÁªàÊ≠¢ÔºåÁ∫øÁ®ãÊ±†ÂàõÂª∫Êñ∞Á∫øÁ®ãÊõø‰ª£Ôºõ‰ΩøÁî®`submit()`Êó∂ÔºåÂºÇÂ∏∏Ë¢´Â∞ÅË£ÖÂú®`Future`‰∏≠ÔºåÁ∫øÁ®ãÁªßÁª≠Â§çÁî®„ÄÇ

ËøôÁßçËÆæËÆ°ÂÖÅËÆ∏`submit()`Êèê‰æõÊõ¥ÁÅµÊ¥ªÁöÑÈîôËØØÂ§ÑÁêÜÊú∫Âà∂ÔºåÂõ†‰∏∫ÂÆÉÂÖÅËÆ∏Ë∞ÉÁî®ËÄÖÂÜ≥ÂÆöÂ¶Ç‰ΩïÂ§ÑÁêÜÂºÇÂ∏∏ÔºåËÄå`execute()`ÂàôÈÄÇÁî®‰∫éÈÇ£‰∫õ‰∏çÈúÄË¶ÅÂÖ≥Ê≥®ÊâßË°åÁªìÊûúÁöÑÂú∫ÊôØ„ÄÇ

ÂÖ∑‰ΩìÁöÑÊ∫êÁ†ÅÂàÜÊûêÂèØ‰ª•ÂèÇËÄÉËøôÁØáÔºö[Á∫øÁ®ãÊ±†‰∏≠Á∫øÁ®ãÂºÇÂ∏∏ÂêéÔºöÈîÄÊØÅËøòÊòØÂ§çÁî®Ôºü - ‰∫¨‰∏úÊäÄÊúØ](https://mp.weixin.qq.com/s/9ODjdUU-EwQFF5PrnzOGfw)„ÄÇ

### ‚≠êÔ∏èÂ¶Ç‰ΩïÁªôÁ∫øÁ®ãÊ±†ÂëΩÂêçÔºü

ÂàùÂßãÂåñÁ∫øÁ®ãÊ±†ÁöÑÊó∂ÂÄôÈúÄË¶ÅÊòæÁ§∫ÂëΩÂêçÔºàËÆæÁΩÆÁ∫øÁ®ãÊ±†ÂêçÁß∞ÂâçÁºÄÔºâÔºåÊúâÂà©‰∫éÂÆö‰ΩçÈóÆÈ¢ò„ÄÇ

ÈªòËÆ§ÊÉÖÂÜµ‰∏ãÂàõÂª∫ÁöÑÁ∫øÁ®ãÂêçÂ≠óÁ±ª‰ºº `pool-1-thread-n` ËøôÊ†∑ÁöÑÔºåÊ≤°Êúâ‰∏öÂä°Âê´‰πâÔºå‰∏çÂà©‰∫éÊàë‰ª¨ÂÆö‰ΩçÈóÆÈ¢ò„ÄÇ

ÁªôÁ∫øÁ®ãÊ±†ÈáåÁöÑÁ∫øÁ®ãÂëΩÂêçÈÄöÂ∏∏Êúâ‰∏ãÈù¢‰∏§ÁßçÊñπÂºèÔºö

**1„ÄÅÂà©Áî® guava ÁöÑ `ThreadFactoryBuilder`**

```java
ThreadFactory threadFactory = new ThreadFactoryBuilder()
                        .setNameFormat(threadNamePrefix + "-%d")
                        .setDaemon(true).build();
ExecutorService threadPool = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit.MINUTES, workQueue, threadFactory);
```

**2„ÄÅËá™Â∑±ÂÆûÁé∞ `ThreadFactory`„ÄÇ**

```java
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * Á∫øÁ®ãÂ∑•ÂéÇÔºåÂÆÉËÆæÁΩÆÁ∫øÁ®ãÂêçÁß∞ÔºåÊúâÂà©‰∫éÊàë‰ª¨ÂÆö‰ΩçÈóÆÈ¢ò„ÄÇ
 */
public final class NamingThreadFactory implements ThreadFactory {

    private final AtomicInteger threadNum = new AtomicInteger();
    private final String name;

    /**
     * ÂàõÂª∫‰∏Ä‰∏™Â∏¶ÂêçÂ≠óÁöÑÁ∫øÁ®ãÊ±†Áîü‰∫ßÂ∑•ÂéÇ
     */
    public NamingThreadFactory(String name) {
        this.name = name;
    }

    @Override
    public Thread newThread(Runnable r) {
        Thread t = new Thread(r);
        t.setName(name + " [#" + threadNum.incrementAndGet() + "]");
        return t;
    }
}
```

### Â¶Ç‰ΩïËÆæÂÆöÁ∫øÁ®ãÊ±†ÁöÑÂ§ßÂ∞èÔºü

ÂæàÂ§ö‰∫∫ÁîöËá≥ÂèØËÉΩÈÉΩ‰ºöËßâÂæóÊääÁ∫øÁ®ãÊ±†ÈÖçÁΩÆËøáÂ§ß‰∏ÄÁÇπÊØîËæÉÂ•ΩÔºÅÊàëËßâÂæóËøôÊòéÊòæÊòØÊúâÈóÆÈ¢òÁöÑ„ÄÇÂ∞±ÊãøÊàë‰ª¨ÁîüÊ¥ª‰∏≠ÈùûÂ∏∏Â∏∏ËßÅÁöÑ‰∏Ä‰æãÂ≠êÊù•ËØ¥Ôºö**Âπ∂‰∏çÊòØ‰∫∫Â§öÂ∞±ËÉΩÊää‰∫ãÊÉÖÂÅöÂ•ΩÔºåÂ¢ûÂä†‰∫ÜÊ≤üÈÄö‰∫§ÊµÅÊàêÊú¨„ÄÇ‰Ω†Êú¨Êù•‰∏Ä‰ª∂‰∫ãÊÉÖÂè™ÈúÄË¶Å 3 ‰∏™‰∫∫ÂÅöÔºå‰Ω†Á°¨ÊòØÊãâÊù•‰∫Ü 6 ‰∏™‰∫∫Ôºå‰ºöÊèêÂçáÂÅö‰∫ãÊïàÁéáÂòõÔºüÊàëÊÉ≥Âπ∂‰∏ç‰ºö„ÄÇ** Á∫øÁ®ãÊï∞ÈáèËøáÂ§öÁöÑÂΩ±Âìç‰πüÊòØÂíåÊàë‰ª¨ÂàÜÈÖçÂ§öÂ∞ë‰∫∫ÂÅö‰∫ãÊÉÖ‰∏ÄÊ†∑ÔºåÂØπ‰∫éÂ§öÁ∫øÁ®ãËøô‰∏™Âú∫ÊôØÊù•ËØ¥‰∏ªË¶ÅÊòØÂ¢ûÂä†‰∫Ü**‰∏ä‰∏ãÊñáÂàáÊç¢**ÊàêÊú¨„ÄÇ‰∏çÊ∏ÖÊ•ö‰ªÄ‰πàÊòØ‰∏ä‰∏ãÊñáÂàáÊç¢ÁöÑËØùÔºåÂèØ‰ª•ÁúãÊàë‰∏ãÈù¢ÁöÑ‰ªãÁªç„ÄÇ

> ‰∏ä‰∏ãÊñáÂàáÊç¢Ôºö
>
> Â§öÁ∫øÁ®ãÁºñÁ®ã‰∏≠‰∏ÄËà¨Á∫øÁ®ãÁöÑ‰∏™Êï∞ÈÉΩÂ§ß‰∫é CPU Ê†∏ÂøÉÁöÑ‰∏™Êï∞ÔºåËÄå‰∏Ä‰∏™ CPU Ê†∏ÂøÉÂú®‰ªªÊÑèÊó∂ÂàªÂè™ËÉΩË¢´‰∏Ä‰∏™Á∫øÁ®ã‰ΩøÁî®Ôºå‰∏∫‰∫ÜËÆ©Ëøô‰∫õÁ∫øÁ®ãÈÉΩËÉΩÂæóÂà∞ÊúâÊïàÊâßË°åÔºåCPU ÈááÂèñÁöÑÁ≠ñÁï•ÊòØ‰∏∫ÊØè‰∏™Á∫øÁ®ãÂàÜÈÖçÊó∂Èó¥ÁâáÂπ∂ËΩÆËΩ¨ÁöÑÂΩ¢Âºè„ÄÇÂΩì‰∏Ä‰∏™Á∫øÁ®ãÁöÑÊó∂Èó¥ÁâáÁî®ÂÆåÁöÑÊó∂ÂÄôÂ∞±‰ºöÈáçÊñ∞Â§Ñ‰∫éÂ∞±Áª™Áä∂ÊÄÅËÆ©ÁªôÂÖ∂‰ªñÁ∫øÁ®ã‰ΩøÁî®ÔºåËøô‰∏™ËøáÁ®ãÂ∞±Â±û‰∫é‰∏ÄÊ¨°‰∏ä‰∏ãÊñáÂàáÊç¢„ÄÇÊ¶ÇÊã¨Êù•ËØ¥Â∞±ÊòØÔºöÂΩìÂâç‰ªªÂä°Âú®ÊâßË°åÂÆå CPU Êó∂Èó¥ÁâáÂàáÊç¢Âà∞Âè¶‰∏Ä‰∏™‰ªªÂä°‰πãÂâç‰ºöÂÖà‰øùÂ≠òËá™Â∑±ÁöÑÁä∂ÊÄÅÔºå‰ª•‰æø‰∏ãÊ¨°ÂÜçÂàáÊç¢ÂõûËøô‰∏™‰ªªÂä°Êó∂ÔºåÂèØ‰ª•ÂÜçÂä†ËΩΩËøô‰∏™‰ªªÂä°ÁöÑÁä∂ÊÄÅ„ÄÇ**‰ªªÂä°‰ªé‰øùÂ≠òÂà∞ÂÜçÂä†ËΩΩÁöÑËøáÁ®ãÂ∞±ÊòØ‰∏ÄÊ¨°‰∏ä‰∏ãÊñáÂàáÊç¢**„ÄÇ
>
> ‰∏ä‰∏ãÊñáÂàáÊç¢ÈÄöÂ∏∏ÊòØËÆ°ÁÆóÂØÜÈõÜÂûãÁöÑ„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÂÆÉÈúÄË¶ÅÁõ∏ÂΩìÂèØËßÇÁöÑÂ§ÑÁêÜÂô®Êó∂Èó¥ÔºåÂú®ÊØèÁßíÂá†ÂçÅ‰∏äÁôæÊ¨°ÁöÑÂàáÊç¢‰∏≠ÔºåÊØèÊ¨°ÂàáÊç¢ÈÉΩÈúÄË¶ÅÁ∫≥ÁßíÈáèÁ∫ßÁöÑÊó∂Èó¥„ÄÇÊâÄ‰ª•Ôºå‰∏ä‰∏ãÊñáÂàáÊç¢ÂØπÁ≥ªÁªüÊù•ËØ¥ÊÑèÂë≥ÁùÄÊ∂àËÄóÂ§ßÈáèÁöÑ CPU Êó∂Èó¥Ôºå‰∫ãÂÆû‰∏äÔºåÂèØËÉΩÊòØÊìç‰ΩúÁ≥ªÁªü‰∏≠Êó∂Èó¥Ê∂àËÄóÊúÄÂ§ßÁöÑÊìç‰Ωú„ÄÇ
>
> Linux Áõ∏ÊØî‰∏éÂÖ∂‰ªñÊìç‰ΩúÁ≥ªÁªüÔºàÂåÖÊã¨ÂÖ∂‰ªñÁ±ª Unix Á≥ªÁªüÔºâÊúâÂæàÂ§öÁöÑ‰ºòÁÇπÔºåÂÖ∂‰∏≠Êúâ‰∏ÄÈ°πÂ∞±ÊòØÔºåÂÖ∂‰∏ä‰∏ãÊñáÂàáÊç¢ÂíåÊ®°ÂºèÂàáÊç¢ÁöÑÊó∂Èó¥Ê∂àËÄóÈùûÂ∏∏Â∞ë„ÄÇ

Á±ªÊØî‰∫éÁé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑ‰∫∫Á±ªÈÄöËøáÂêà‰ΩúÂÅöÊüê‰ª∂‰∫ãÊÉÖÔºåÊàë‰ª¨ÂèØ‰ª•ËÇØÂÆöÁöÑ‰∏ÄÁÇπÊòØÁ∫øÁ®ãÊ±†Â§ßÂ∞èËÆæÁΩÆËøáÂ§ßÊàñËÄÖËøáÂ∞èÈÉΩ‰ºöÊúâÈóÆÈ¢òÔºåÂêàÈÄÇÁöÑÊâçÊòØÊúÄÂ•Ω„ÄÇ

- Â¶ÇÊûúÊàë‰ª¨ËÆæÁΩÆÁöÑÁ∫øÁ®ãÊ±†Êï∞ÈáèÂ§™Â∞èÁöÑËØùÔºåÂ¶ÇÊûúÂêå‰∏ÄÊó∂Èó¥ÊúâÂ§ßÈáè‰ªªÂä°/ËØ∑Ê±ÇÈúÄË¶ÅÂ§ÑÁêÜÔºåÂèØËÉΩ‰ºöÂØºËá¥Â§ßÈáèÁöÑËØ∑Ê±Ç/‰ªªÂä°Âú®‰ªªÂä°ÈòüÂàó‰∏≠ÊéíÈòüÁ≠âÂæÖÊâßË°åÔºåÁîöËá≥‰ºöÂá∫Áé∞‰ªªÂä°ÈòüÂàóÊª°‰∫Ü‰πãÂêé‰ªªÂä°/ËØ∑Ê±ÇÊó†Ê≥ïÂ§ÑÁêÜÁöÑÊÉÖÂÜµÔºåÊàñËÄÖÂ§ßÈáè‰ªªÂä°Â†ÜÁßØÂú®‰ªªÂä°ÈòüÂàóÂØºËá¥ OOM„ÄÇËøôÊ†∑ÂæàÊòéÊòæÊòØÊúâÈóÆÈ¢òÁöÑÔºåCPU Ê†πÊú¨Ê≤°ÊúâÂæóÂà∞ÂÖÖÂàÜÂà©Áî®„ÄÇ
- Â¶ÇÊûúÊàë‰ª¨ËÆæÁΩÆÁ∫øÁ®ãÊï∞ÈáèÂ§™Â§ßÔºåÂ§ßÈáèÁ∫øÁ®ãÂèØËÉΩ‰ºöÂêåÊó∂Âú®‰∫âÂèñ CPU ËµÑÊ∫êÔºåËøôÊ†∑‰ºöÂØºËá¥Â§ßÈáèÁöÑ‰∏ä‰∏ãÊñáÂàáÊç¢Ôºå‰ªéËÄåÂ¢ûÂä†Á∫øÁ®ãÁöÑÊâßË°åÊó∂Èó¥ÔºåÂΩ±Âìç‰∫ÜÊï¥‰ΩìÊâßË°åÊïàÁéá„ÄÇ

Êúâ‰∏Ä‰∏™ÁÆÄÂçïÂπ∂‰∏îÈÄÇÁî®Èù¢ÊØîËæÉÂπøÁöÑÂÖ¨ÂºèÔºö

- **CPU ÂØÜÈõÜÂûã‰ªªÂä°(N+1)Ôºö** ËøôÁßç‰ªªÂä°Ê∂àËÄóÁöÑ‰∏ªË¶ÅÊòØ CPU ËµÑÊ∫êÔºåÂèØ‰ª•Â∞ÜÁ∫øÁ®ãÊï∞ËÆæÁΩÆ‰∏∫ NÔºàCPU Ê†∏ÂøÉÊï∞Ôºâ+1„ÄÇÊØî CPU Ê†∏ÂøÉÊï∞Â§öÂá∫Êù•ÁöÑ‰∏Ä‰∏™Á∫øÁ®ãÊòØ‰∏∫‰∫ÜÈò≤Ê≠¢Á∫øÁ®ãÂÅ∂ÂèëÁöÑÁº∫È°µ‰∏≠Êñ≠ÔºåÊàñËÄÖÂÖ∂ÂÆÉÂéüÂõ†ÂØºËá¥ÁöÑ‰ªªÂä°ÊöÇÂÅúËÄåÂ∏¶Êù•ÁöÑÂΩ±Âìç„ÄÇ‰∏ÄÊó¶‰ªªÂä°ÊöÇÂÅúÔºåCPU Â∞±‰ºöÂ§Ñ‰∫éÁ©∫Èó≤Áä∂ÊÄÅÔºåËÄåÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÂ§öÂá∫Êù•ÁöÑ‰∏Ä‰∏™Á∫øÁ®ãÂ∞±ÂèØ‰ª•ÂÖÖÂàÜÂà©Áî® CPU ÁöÑÁ©∫Èó≤Êó∂Èó¥„ÄÇ
- **I/O ÂØÜÈõÜÂûã‰ªªÂä°(2N)Ôºö** ËøôÁßç‰ªªÂä°Â∫îÁî®Ëµ∑Êù•ÔºåÁ≥ªÁªü‰ºöÁî®Â§ßÈÉ®ÂàÜÁöÑÊó∂Èó¥Êù•Â§ÑÁêÜ I/O ‰∫§‰∫íÔºåËÄåÁ∫øÁ®ãÂú®Â§ÑÁêÜ I/O ÁöÑÊó∂Èó¥ÊÆµÂÜÖ‰∏ç‰ºöÂç†Áî® CPU Êù•Â§ÑÁêÜÔºåËøôÊó∂Â∞±ÂèØ‰ª•Â∞Ü CPU ‰∫§Âá∫ÁªôÂÖ∂ÂÆÉÁ∫øÁ®ã‰ΩøÁî®„ÄÇÂõ†Ê≠§Âú® I/O ÂØÜÈõÜÂûã‰ªªÂä°ÁöÑÂ∫îÁî®‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•Â§öÈÖçÁΩÆ‰∏Ä‰∫õÁ∫øÁ®ãÔºåÂÖ∑‰ΩìÁöÑËÆ°ÁÆóÊñπÊ≥ïÊòØ 2N„ÄÇ

**Â¶Ç‰ΩïÂà§Êñ≠ÊòØ CPU ÂØÜÈõÜ‰ªªÂä°ËøòÊòØ IO ÂØÜÈõÜ‰ªªÂä°Ôºü**

CPU ÂØÜÈõÜÂûãÁÆÄÂçïÁêÜËß£Â∞±ÊòØÂà©Áî® CPU ËÆ°ÁÆóËÉΩÂäõÁöÑ‰ªªÂä°ÊØîÂ¶Ç‰Ω†Âú®ÂÜÖÂ≠ò‰∏≠ÂØπÂ§ßÈáèÊï∞ÊçÆËøõË°åÊéíÂ∫è„ÄÇ‰ΩÜÂá°Ê∂âÂèäÂà∞ÁΩëÁªúËØªÂèñÔºåÊñá‰ª∂ËØªÂèñËøôÁ±ªÈÉΩÊòØ IO ÂØÜÈõÜÂûãÔºåËøôÁ±ª‰ªªÂä°ÁöÑÁâπÁÇπÊòØ CPU ËÆ°ÁÆóËÄóË¥πÊó∂Èó¥Áõ∏ÊØî‰∫éÁ≠âÂæÖ IO Êìç‰ΩúÂÆåÊàêÁöÑÊó∂Èó¥Êù•ËØ¥ÂæàÂ∞ëÔºåÂ§ßÈÉ®ÂàÜÊó∂Èó¥ÈÉΩËä±Âú®‰∫ÜÁ≠âÂæÖ IO Êìç‰ΩúÂÆåÊàê‰∏ä„ÄÇ

> üåà ÊãìÂ±ï‰∏Ä‰∏ãÔºàÂèÇËßÅÔºö[issue#1737](https://github.com/Snailclimb/JavaGuide/issues/1737)ÔºâÔºö
>
> Á∫øÁ®ãÊï∞Êõ¥‰∏•Ë∞®ÁöÑËÆ°ÁÆóÁöÑÊñπÊ≥ïÂ∫îËØ•ÊòØÔºö`ÊúÄ‰Ω≥Á∫øÁ®ãÊï∞ = NÔºàCPU Ê†∏ÂøÉÊï∞Ôºâ‚àóÔºà1+WTÔºàÁ∫øÁ®ãÁ≠âÂæÖÊó∂Èó¥Ôºâ/STÔºàÁ∫øÁ®ãËÆ°ÁÆóÊó∂Èó¥ÔºâÔºâ`ÔºåÂÖ∂‰∏≠ `WTÔºàÁ∫øÁ®ãÁ≠âÂæÖÊó∂Èó¥Ôºâ=Á∫øÁ®ãËøêË°åÊÄªÊó∂Èó¥ - STÔºàÁ∫øÁ®ãËÆ°ÁÆóÊó∂Èó¥Ôºâ`„ÄÇ
>
> Á∫øÁ®ãÁ≠âÂæÖÊó∂Èó¥ÊâÄÂç†ÊØî‰æãË∂äÈ´òÔºåÈúÄË¶ÅË∂äÂ§öÁ∫øÁ®ã„ÄÇÁ∫øÁ®ãËÆ°ÁÆóÊó∂Èó¥ÊâÄÂç†ÊØî‰æãË∂äÈ´òÔºåÈúÄË¶ÅË∂äÂ∞ëÁ∫øÁ®ã„ÄÇ
>
> Êàë‰ª¨ÂèØ‰ª•ÈÄöËøá JDK Ëá™Â∏¶ÁöÑÂ∑•ÂÖ∑ VisualVM Êù•Êü•Áúã `WT/ST` ÊØî‰æã„ÄÇ
>
> CPU ÂØÜÈõÜÂûã‰ªªÂä°ÁöÑ `WT/ST` Êé•ËøëÊàñËÄÖÁ≠â‰∫é 0ÔºåÂõ†Ê≠§Ôºå Á∫øÁ®ãÊï∞ÂèØ‰ª•ËÆæÁΩÆ‰∏∫ NÔºàCPU Ê†∏ÂøÉÊï∞Ôºâ‚àóÔºà1+0Ôºâ= NÔºåÂíåÊàë‰ª¨‰∏äÈù¢ËØ¥ÁöÑ NÔºàCPU Ê†∏ÂøÉÊï∞Ôºâ+1 Â∑Æ‰∏çÂ§ö„ÄÇ
>
> IO ÂØÜÈõÜÂûã‰ªªÂä°‰∏ãÔºåÂá†‰πéÂÖ®ÊòØÁ∫øÁ®ãÁ≠âÂæÖÊó∂Èó¥Ôºå‰ªéÁêÜËÆ∫‰∏äÊù•ËØ¥Ôºå‰Ω†Â∞±ÂèØ‰ª•Â∞ÜÁ∫øÁ®ãÊï∞ËÆæÁΩÆ‰∏∫ 2NÔºàÊåâÈÅìÁêÜÊù•ËØ¥ÔºåWT/ST ÁöÑÁªìÊûúÂ∫îËØ•ÊØîËæÉÂ§ßÔºåËøôÈáåÈÄâÊã© 2N ÁöÑÂéüÂõ†Â∫îËØ•ÊòØ‰∏∫‰∫ÜÈÅøÂÖçÂàõÂª∫ËøáÂ§öÁ∫øÁ®ãÂêßÔºâ„ÄÇ

ÂÖ¨Âºè‰πüÂè™ÊòØÂèÇËÄÉÔºåÂÖ∑‰ΩìËøòÊòØË¶ÅÊ†πÊçÆÈ°πÁõÆÂÆûÈôÖÁ∫ø‰∏äËøêË°åÊÉÖÂÜµÊù•Âä®ÊÄÅË∞ÉÊï¥„ÄÇÊàëÂú®ÂêéÈù¢‰ªãÁªçÁöÑÁæéÂõ¢ÁöÑÁ∫øÁ®ãÊ±†ÂèÇÊï∞Âä®ÊÄÅÈÖçÁΩÆËøôÁßçÊñπÊ°àÂ∞±ÈùûÂ∏∏‰∏çÈîôÔºåÂæàÂÆûÁî®ÔºÅ

### ‚≠êÔ∏èÂ¶Ç‰ΩïÂä®ÊÄÅ‰øÆÊîπÁ∫øÁ®ãÊ±†ÁöÑÂèÇÊï∞Ôºü

ÁæéÂõ¢ÊäÄÊúØÂõ¢ÈòüÂú®[„ÄäJava Á∫øÁ®ãÊ±†ÂÆûÁé∞ÂéüÁêÜÂèäÂÖ∂Âú®ÁæéÂõ¢‰∏öÂä°‰∏≠ÁöÑÂÆûË∑µ„Äã](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)ËøôÁØáÊñáÁ´†‰∏≠‰ªãÁªçÂà∞ÂØπÁ∫øÁ®ãÊ±†ÂèÇÊï∞ÂÆûÁé∞ÂèØËá™ÂÆö‰πâÈÖçÁΩÆÁöÑÊÄùË∑ØÂíåÊñπÊ≥ï„ÄÇ

ÁæéÂõ¢ÊäÄÊúØÂõ¢ÈòüÁöÑÊÄùË∑ØÊòØ‰∏ªË¶ÅÂØπÁ∫øÁ®ãÊ±†ÁöÑÊ†∏ÂøÉÂèÇÊï∞ÂÆûÁé∞Ëá™ÂÆö‰πâÂèØÈÖçÁΩÆ„ÄÇËøô‰∏â‰∏™Ê†∏ÂøÉÂèÇÊï∞ÊòØÔºö

- **`corePoolSize` :** Ê†∏ÂøÉÁ∫øÁ®ãÊï∞ÂÆö‰πâ‰∫ÜÊúÄÂ∞èÂèØ‰ª•ÂêåÊó∂ËøêË°åÁöÑÁ∫øÁ®ãÊï∞Èáè„ÄÇ
- **`maximumPoolSize` :** ÂΩìÈòüÂàó‰∏≠Â≠òÊîæÁöÑ‰ªªÂä°ËææÂà∞ÈòüÂàóÂÆπÈáèÁöÑÊó∂ÂÄôÔºåÂΩìÂâçÂèØ‰ª•ÂêåÊó∂ËøêË°åÁöÑÁ∫øÁ®ãÊï∞ÈáèÂèò‰∏∫ÊúÄÂ§ßÁ∫øÁ®ãÊï∞„ÄÇ
- **`workQueue`:** ÂΩìÊñ∞‰ªªÂä°Êù•ÁöÑÊó∂ÂÄô‰ºöÂÖàÂà§Êñ≠ÂΩìÂâçËøêË°åÁöÑÁ∫øÁ®ãÊï∞ÈáèÊòØÂê¶ËææÂà∞Ê†∏ÂøÉÁ∫øÁ®ãÊï∞ÔºåÂ¶ÇÊûúËææÂà∞ÁöÑËØùÔºåÊñ∞‰ªªÂä°Â∞±‰ºöË¢´Â≠òÊîæÂú®ÈòüÂàó‰∏≠„ÄÇ

**‰∏∫‰ªÄ‰πàÊòØËøô‰∏â‰∏™ÂèÇÊï∞Ôºü**

ÊàëÂú®[Java Á∫øÁ®ãÊ±†ËØ¶Ëß£](https://javaguide.cn/java/concurrent/java-thread-pool-summary.html) ËøôÁØáÊñáÁ´†‰∏≠Â∞±ËØ¥ËøáËøô‰∏â‰∏™ÂèÇÊï∞ÊòØ `ThreadPoolExecutor` ÊúÄÈáçË¶ÅÁöÑÂèÇÊï∞ÔºåÂÆÉ‰ª¨Âü∫Êú¨ÂÜ≥ÂÆö‰∫ÜÁ∫øÁ®ãÊ±†ÂØπ‰∫é‰ªªÂä°ÁöÑÂ§ÑÁêÜÁ≠ñÁï•„ÄÇ

**Â¶Ç‰ΩïÊîØÊåÅÂèÇÊï∞Âä®ÊÄÅÈÖçÁΩÆÔºü** ‰∏îÁúã `ThreadPoolExecutor` Êèê‰æõÁöÑ‰∏ãÈù¢Ëøô‰∫õÊñπÊ≥ï„ÄÇ

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/threadpoolexecutor-methods.png)

Ê†ºÂ§ñÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØ`corePoolSize`Ôºå Á®ãÂ∫èËøêË°åÊúüÈó¥ÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨Ë∞ÉÁî® `setCorePoolSize()`Ëøô‰∏™ÊñπÊ≥ïÁöÑËØùÔºåÁ∫øÁ®ãÊ±†‰ºöÈ¶ñÂÖàÂà§Êñ≠ÂΩìÂâçÂ∑•‰ΩúÁ∫øÁ®ãÊï∞ÊòØÂê¶Â§ß‰∫é`corePoolSize`ÔºåÂ¶ÇÊûúÂ§ß‰∫éÁöÑËØùÂ∞±‰ºöÂõûÊî∂Â∑•‰ΩúÁ∫øÁ®ã„ÄÇ

Âè¶Â§ñÔºå‰Ω†‰πüÁúãÂà∞‰∫Ü‰∏äÈù¢Âπ∂Ê≤°ÊúâÂä®ÊÄÅÊåáÂÆöÈòüÂàóÈïøÂ∫¶ÁöÑÊñπÊ≥ïÔºåÁæéÂõ¢ÁöÑÊñπÂºèÊòØËá™ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âè´ÂÅö `ResizableCapacityLinkedBlockIngQueue` ÁöÑÈòüÂàóÔºà‰∏ªË¶ÅÂ∞±ÊòØÊää`LinkedBlockingQueue`ÁöÑ capacity Â≠óÊÆµÁöÑ final ÂÖ≥ÈîÆÂ≠ó‰øÆÈ•∞ÁªôÂéªÊéâ‰∫ÜÔºåËÆ©ÂÆÉÂèò‰∏∫ÂèØÂèòÁöÑÔºâ„ÄÇ

ÊúÄÁªàÂÆûÁé∞ÁöÑÂèØÂä®ÊÄÅ‰øÆÊîπÁ∫øÁ®ãÊ±†ÂèÇÊï∞ÊïàÊûúÂ¶Ç‰∏ã„ÄÇüëèüëèüëè

![Âä®ÊÄÅÈÖçÁΩÆÁ∫øÁ®ãÊ±†ÂèÇÊï∞ÊúÄÁªàÊïàÊûú](https://oss.javaguide.cn/github/javaguide/java/concurrent/meituan-dynamically-configuring-thread-pool-parameters.png)

ËøòÊ≤°ÁúãÂ§üÔºüÊàëÂú®[„ÄäÂêéÁ´ØÈù¢ËØïÈ´òÈ¢ëÁ≥ªÁªüËÆæËÆ°&Âú∫ÊôØÈ¢ò„Äã](https://javaguide.cn/zhuanlan/back-end-interview-high-frequency-system-design-and-scenario-questions.html)‰∏≠ËØ¶ÁªÜ‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïËÆæËÆ°‰∏Ä‰∏™Âä®ÊÄÅÁ∫øÁ®ãÊ±†ÔºåËøô‰πüÊòØÈù¢ËØï‰∏≠Â∏∏ÈóÆÁöÑ‰∏ÄÈÅìÁ≥ªÁªüËÆæËÆ°È¢ò„ÄÇ

![„ÄäÂêéÁ´ØÈù¢ËØïÈ´òÈ¢ëÁ≥ªÁªüËÆæËÆ°&Âú∫ÊôØÈ¢ò„Äã](https://oss.javaguide.cn/xingqiu/back-end-interview-high-frequency-system-design-and-scenario-questions-fengmian.png)

Â¶ÇÊûúÊàë‰ª¨ÁöÑÈ°πÁõÆ‰πüÊÉ≥Ë¶ÅÂÆûÁé∞ËøôÁßçÊïàÊûúÁöÑËØùÔºåÂèØ‰ª•ÂÄüÂä©Áé∞ÊàêÁöÑÂºÄÊ∫êÈ°πÁõÆÔºö

- **[Hippo4j](https://github.com/opengoofy/hippo4j)**ÔºöÂºÇÊ≠•Á∫øÁ®ãÊ±†Ê°ÜÊû∂ÔºåÊîØÊåÅÁ∫øÁ®ãÊ±†Âä®ÊÄÅÂèòÊõ¥&ÁõëÊéß&Êä•Ë≠¶ÔºåÊó†ÈúÄ‰øÆÊîπ‰ª£Á†ÅËΩªÊùæÂºïÂÖ•„ÄÇÊîØÊåÅÂ§öÁßç‰ΩøÁî®Ê®°ÂºèÔºåËΩªÊùæÂºïÂÖ•ÔºåËá¥Âäõ‰∫éÊèêÈ´òÁ≥ªÁªüËøêË°å‰øùÈöúËÉΩÂäõ„ÄÇ
- **[Dynamic TP](https://github.com/dromara/dynamic-tp)**ÔºöËΩªÈáèÁ∫ßÂä®ÊÄÅÁ∫øÁ®ãÊ±†ÔºåÂÜÖÁΩÆÁõëÊéßÂëäË≠¶ÂäüËÉΩÔºåÈõÜÊàê‰∏âÊñπ‰∏≠Èó¥‰ª∂Á∫øÁ®ãÊ±†ÁÆ°ÁêÜÔºåÂü∫‰∫é‰∏ªÊµÅÈÖçÁΩÆ‰∏≠ÂøÉÔºàÂ∑≤ÊîØÊåÅ Nacos„ÄÅApolloÔºåZookeeper„ÄÅConsul„ÄÅEtcdÔºåÂèØÈÄöËøá SPI Ëá™ÂÆö‰πâÂÆûÁé∞Ôºâ„ÄÇ

### ‚≠êÔ∏èÂ¶Ç‰ΩïËÆæËÆ°‰∏Ä‰∏™ËÉΩÂ§üÊ†πÊçÆ‰ªªÂä°ÁöÑ‰ºòÂÖàÁ∫ßÊù•ÊâßË°åÁöÑÁ∫øÁ®ãÊ±†Ôºü

ËøôÊòØ‰∏Ä‰∏™Â∏∏ËßÅÁöÑÈù¢ËØïÈóÆÈ¢òÔºåÊú¨Ë¥®ÂÖ∂ÂÆûËøòÊòØÂú®ËÄÉÂØüÊ±ÇËÅåËÄÖÂØπ‰∫éÁ∫øÁ®ãÊ±†‰ª•ÂèäÈòªÂ°ûÈòüÂàóÁöÑÊéåÊè°„ÄÇ

Êàë‰ª¨‰∏äÈù¢‰πüÊèêÂà∞‰∫ÜÔºå‰∏çÂêåÁöÑÁ∫øÁ®ãÊ±†‰ºöÈÄâÁî®‰∏çÂêåÁöÑÈòªÂ°ûÈòüÂàó‰Ωú‰∏∫‰ªªÂä°ÈòüÂàóÔºåÊØîÂ¶Ç`FixedThreadPool` ‰ΩøÁî®ÁöÑÊòØ`LinkedBlockingQueue`ÔºàÊúâÁïåÈòüÂàóÔºâÔºåÈªòËÆ§ÊûÑÈÄ†Âô®ÂàùÂßãÁöÑÈòüÂàóÈïøÂ∫¶‰∏∫ `Integer.MAX_VALUE` ÔºåÁî±‰∫éÈòüÂàóÊ∞∏Ëøú‰∏ç‰ºöË¢´ÊîæÊª°ÔºåÂõ†Ê≠§`FixedThreadPool`ÊúÄÂ§öÂè™ËÉΩÂàõÂª∫Ê†∏ÂøÉÁ∫øÁ®ãÊï∞ÁöÑÁ∫øÁ®ã„ÄÇ

ÂÅáÂ¶ÇÊàë‰ª¨ÈúÄË¶ÅÂÆûÁé∞‰∏Ä‰∏™‰ºòÂÖàÁ∫ß‰ªªÂä°Á∫øÁ®ãÊ±†ÁöÑËØùÔºåÈÇ£ÂèØ‰ª•ËÄÉËôë‰ΩøÁî® `PriorityBlockingQueue` Ôºà‰ºòÂÖàÁ∫ßÈòªÂ°ûÈòüÂàóÔºâ‰Ωú‰∏∫‰ªªÂä°ÈòüÂàóÔºà`ThreadPoolExecutor` ÁöÑÊûÑÈÄ†ÂáΩÊï∞Êúâ‰∏Ä‰∏™ `workQueue` ÂèÇÊï∞ÂèØ‰ª•‰º†ÂÖ•‰ªªÂä°ÈòüÂàóÔºâ„ÄÇ

![ThreadPoolExecutorÊûÑÈÄ†ÂáΩÊï∞](https://oss.javaguide.cn/github/javaguide/java/concurrent/common-parameters-of-threadpool-workqueue.jpg)

`PriorityBlockingQueue` ÊòØ‰∏Ä‰∏™ÊîØÊåÅ‰ºòÂÖàÁ∫ßÁöÑÊó†ÁïåÈòªÂ°ûÈòüÂàóÔºåÂèØ‰ª•Áúã‰ΩúÊòØÁ∫øÁ®ãÂÆâÂÖ®ÁöÑ `PriorityQueue`Ôºå‰∏§ËÄÖÂ∫ïÂ±ÇÈÉΩÊòØ‰ΩøÁî®Â∞èÈ°∂Â†ÜÂΩ¢ÂºèÁöÑ‰∫åÂèâÂ†ÜÔºåÂç≥ÂÄºÊúÄÂ∞èÁöÑÂÖÉÁ¥†‰ºòÂÖàÂá∫Èòü„ÄÇ‰∏çËøáÔºå`PriorityQueue` ‰∏çÊîØÊåÅÈòªÂ°ûÊìç‰Ωú„ÄÇ

Ë¶ÅÊÉ≥ËÆ© `PriorityBlockingQueue` ÂÆûÁé∞ÂØπ‰ªªÂä°ÁöÑÊéíÂ∫èÔºå‰º†ÂÖ•ÂÖ∂‰∏≠ÁöÑ‰ªªÂä°ÂøÖÈ°ªÊòØÂÖ∑Â§áÊéíÂ∫èËÉΩÂäõÁöÑÔºåÊñπÂºèÊúâ‰∏§ÁßçÔºö

1. Êèê‰∫§Âà∞Á∫øÁ®ãÊ±†ÁöÑ‰ªªÂä°ÂÆûÁé∞ `Comparable` Êé•Âè£ÔºåÂπ∂ÈáçÂÜô `compareTo` ÊñπÊ≥ïÊù•ÊåáÂÆö‰ªªÂä°‰πãÈó¥ÁöÑ‰ºòÂÖàÁ∫ßÊØîËæÉËßÑÂàô„ÄÇ
2. ÂàõÂª∫ `PriorityBlockingQueue` Êó∂‰º†ÂÖ•‰∏Ä‰∏™ `Comparator` ÂØπË±°Êù•ÊåáÂÆö‰ªªÂä°‰πãÈó¥ÁöÑÊéíÂ∫èËßÑÂàô(Êé®Ëçê)„ÄÇ

‰∏çËøáÔºåËøôÂ≠òÂú®‰∏Ä‰∫õÈ£éÈô©ÂíåÈóÆÈ¢òÔºåÊØîÂ¶ÇÔºö

- `PriorityBlockingQueue` ÊòØÊó†ÁïåÁöÑÔºåÂèØËÉΩÂ†ÜÁßØÂ§ßÈáèÁöÑËØ∑Ê±ÇÔºå‰ªéËÄåÂØºËá¥ OOM„ÄÇ
- ÂèØËÉΩ‰ºöÂØºËá¥È••È•øÈóÆÈ¢òÔºåÂç≥‰Ωé‰ºòÂÖàÁ∫ßÁöÑ‰ªªÂä°ÈïøÊó∂Èó¥Âæó‰∏çÂà∞ÊâßË°å„ÄÇ
- Áî±‰∫éÈúÄË¶ÅÂØπÈòüÂàó‰∏≠ÁöÑÂÖÉÁ¥†ËøõË°åÊéíÂ∫èÊìç‰Ωú‰ª•Âèä‰øùËØÅÁ∫øÁ®ãÂÆâÂÖ®ÔºàÂπ∂ÂèëÊéßÂà∂ÈááÁî®ÁöÑÊòØÂèØÈáçÂÖ•ÈîÅ `ReentrantLock`ÔºâÔºåÂõ†Ê≠§‰ºöÈôç‰ΩéÊÄßËÉΩ„ÄÇ

ÂØπ‰∫é OOM Ëøô‰∏™ÈóÆÈ¢òÁöÑËß£ÂÜ≥ÊØîËæÉÁÆÄÂçïÁ≤óÊö¥ÔºåÂ∞±ÊòØÁªßÊâø`PriorityBlockingQueue` Âπ∂ÈáçÂÜô‰∏Ä‰∏ã `offer` ÊñπÊ≥ï(ÂÖ•Èòü)ÁöÑÈÄªËæëÔºåÂΩìÊèíÂÖ•ÁöÑÂÖÉÁ¥†Êï∞ÈáèË∂ÖËøáÊåáÂÆöÂÄºÂ∞±ËøîÂõû false „ÄÇ

È••È•øÈóÆÈ¢òËøô‰∏™ÂèØ‰ª•ÈÄöËøá‰ºòÂåñËÆæËÆ°Êù•Ëß£ÂÜ≥ÔºàÊØîËæÉÈ∫ªÁÉ¶ÔºâÔºåÊØîÂ¶ÇÁ≠âÂæÖÊó∂Èó¥ËøáÈïøÁöÑ‰ªªÂä°‰ºöË¢´ÁßªÈô§Âπ∂ÈáçÊñ∞Ê∑ªÂä†Âà∞ÈòüÂàó‰∏≠Ôºå‰ΩÜÊòØ‰ºòÂÖàÁ∫ß‰ºöË¢´ÊèêÂçá„ÄÇ

ÂØπ‰∫éÊÄßËÉΩÊñπÈù¢ÁöÑÂΩ±ÂìçÔºåÊòØÊ≤°ÂäûÊ≥ïÈÅøÂÖçÁöÑÔºåÊØïÁ´üÈúÄË¶ÅÂØπ‰ªªÂä°ËøõË°åÊéíÂ∫èÊìç‰Ωú„ÄÇÂπ∂‰∏îÔºåÂØπ‰∫éÂ§ßÈÉ®ÂàÜ‰∏öÂä°Âú∫ÊôØÊù•ËØ¥ÔºåËøôÁÇπÊÄßËÉΩÂΩ±ÂìçÊòØÂèØ‰ª•Êé•ÂèóÁöÑ„ÄÇ

## Future

ÈáçÁÇπÊòØË¶ÅÊéåÊè° `CompletableFuture` ÁöÑ‰ΩøÁî®‰ª•ÂèäÂ∏∏ËßÅÈù¢ËØïÈ¢ò„ÄÇ

Èô§‰∫Ü‰∏ãÈù¢ÁöÑÈù¢ËØïÈ¢ò‰πãÂ§ñÔºåËøòÊé®Ëçê‰Ω†ÁúãÁúãÊàëÂÜôÁöÑËøôÁØáÊñáÁ´†Ôºö [CompletableFuture ËØ¶Ëß£](https://javaguide.cn/java/concurrent/completablefuture-intro.html)„ÄÇ

### Future Á±ªÊúâ‰ªÄ‰πàÁî®Ôºü

`Future` Á±ªÊòØÂºÇÊ≠•ÊÄùÊÉ≥ÁöÑÂÖ∏ÂûãËøêÁî®Ôºå‰∏ªË¶ÅÁî®Âú®‰∏Ä‰∫õÈúÄË¶ÅÊâßË°åËÄóÊó∂‰ªªÂä°ÁöÑÂú∫ÊôØÔºåÈÅøÂÖçÁ®ãÂ∫è‰∏ÄÁõ¥ÂéüÂú∞Á≠âÂæÖËÄóÊó∂‰ªªÂä°ÊâßË°åÂÆåÊàêÔºåÊâßË°åÊïàÁéáÂ§™‰Ωé„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÊòØËøôÊ†∑ÁöÑÔºöÂΩìÊàë‰ª¨ÊâßË°åÊüê‰∏ÄËÄóÊó∂ÁöÑ‰ªªÂä°Êó∂ÔºåÂèØ‰ª•Â∞ÜËøô‰∏™ËÄóÊó∂‰ªªÂä°‰∫§Áªô‰∏Ä‰∏™Â≠êÁ∫øÁ®ãÂéªÂºÇÊ≠•ÊâßË°åÔºåÂêåÊó∂Êàë‰ª¨ÂèØ‰ª•Âπ≤ÁÇπÂÖ∂‰ªñ‰∫ãÊÉÖÔºå‰∏çÁî®ÂÇªÂÇªÁ≠âÂæÖËÄóÊó∂‰ªªÂä°ÊâßË°åÂÆåÊàê„ÄÇÁ≠âÊàë‰ª¨ÁöÑ‰∫ãÊÉÖÂπ≤ÂÆåÂêéÔºåÊàë‰ª¨ÂÜçÈÄöËøá `Future` Á±ªËé∑ÂèñÂà∞ËÄóÊó∂‰ªªÂä°ÁöÑÊâßË°åÁªìÊûú„ÄÇËøôÊ†∑‰∏ÄÊù•ÔºåÁ®ãÂ∫èÁöÑÊâßË°åÊïàÁéáÂ∞±ÊòéÊòæÊèêÈ´ò‰∫Ü„ÄÇ

ËøôÂÖ∂ÂÆûÂ∞±ÊòØÂ§öÁ∫øÁ®ã‰∏≠ÁªèÂÖ∏ÁöÑ **Future Ê®°Âºè**Ôºå‰Ω†ÂèØ‰ª•Â∞ÜÂÖ∂Áúã‰ΩúÊòØ‰∏ÄÁßçËÆæËÆ°Ê®°ÂºèÔºåÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂºÇÊ≠•Ë∞ÉÁî®Ôºå‰∏ªË¶ÅÁî®Âú®Â§öÁ∫øÁ®ãÈ¢ÜÂüüÔºåÂπ∂Èùû Java ËØ≠Ë®ÄÁã¨Êúâ„ÄÇ

Âú® Java ‰∏≠Ôºå`Future` Á±ªÂè™ÊòØ‰∏Ä‰∏™Ê≥õÂûãÊé•Âè£Ôºå‰Ωç‰∫é `java.util.concurrent` ÂåÖ‰∏ãÔºåÂÖ∂‰∏≠ÂÆö‰πâ‰∫Ü 5 ‰∏™ÊñπÊ≥ïÔºå‰∏ªË¶ÅÂåÖÊã¨‰∏ãÈù¢Ëøô 4 ‰∏™ÂäüËÉΩÔºö

- ÂèñÊ∂à‰ªªÂä°Ôºõ
- Âà§Êñ≠‰ªªÂä°ÊòØÂê¶Ë¢´ÂèñÊ∂à;
- Âà§Êñ≠‰ªªÂä°ÊòØÂê¶Â∑≤ÁªèÊâßË°åÂÆåÊàê;
- Ëé∑Âèñ‰ªªÂä°ÊâßË°åÁªìÊûú„ÄÇ

```java
// V ‰ª£Ë°®‰∫ÜFutureÊâßË°åÁöÑ‰ªªÂä°ËøîÂõûÂÄºÁöÑÁ±ªÂûã
public interface Future<V> {
    // ÂèñÊ∂à‰ªªÂä°ÊâßË°å
    // ÊàêÂäüÂèñÊ∂àËøîÂõû trueÔºåÂê¶ÂàôËøîÂõû false
    boolean cancel(boolean mayInterruptIfRunning);
    // Âà§Êñ≠‰ªªÂä°ÊòØÂê¶Ë¢´ÂèñÊ∂à
    boolean isCancelled();
    // Âà§Êñ≠‰ªªÂä°ÊòØÂê¶Â∑≤ÁªèÊâßË°åÂÆåÊàê
    boolean isDone();
    // Ëé∑Âèñ‰ªªÂä°ÊâßË°åÁªìÊûú
    V get() throws InterruptedException, ExecutionException;
    // ÊåáÂÆöÊó∂Èó¥ÂÜÖÊ≤°ÊúâËøîÂõûËÆ°ÁÆóÁªìÊûúÂ∞±ÊäõÂá∫ TimeOutException ÂºÇÂ∏∏
    V get(long timeout, TimeUnit unit)

        throws InterruptedException, ExecutionException, TimeoutExceptio

}
```

ÁÆÄÂçïÁêÜËß£Â∞±ÊòØÔºöÊàëÊúâ‰∏Ä‰∏™‰ªªÂä°ÔºåÊèê‰∫§Áªô‰∫Ü `Future` Êù•Â§ÑÁêÜ„ÄÇ‰ªªÂä°ÊâßË°åÊúüÈó¥ÊàëËá™Â∑±ÂèØ‰ª•ÂéªÂÅö‰ªª‰ΩïÊÉ≥ÂÅöÁöÑ‰∫ãÊÉÖ„ÄÇÂπ∂‰∏îÔºåÂú®ËøôÊúüÈó¥ÊàëËøòÂèØ‰ª•ÂèñÊ∂à‰ªªÂä°‰ª•ÂèäËé∑Âèñ‰ªªÂä°ÁöÑÊâßË°åÁä∂ÊÄÅ„ÄÇ‰∏ÄÊÆµÊó∂Èó¥‰πãÂêéÔºåÊàëÂ∞±ÂèØ‰ª• `Future` ÈÇ£ÈáåÁõ¥Êé•ÂèñÂá∫‰ªªÂä°ÊâßË°åÁªìÊûú„ÄÇ

### Callable Âíå Future Êúâ‰ªÄ‰πàÂÖ≥Á≥ªÔºü

Êàë‰ª¨ÂèØ‰ª•ÈÄöËøá `FutureTask` Êù•ÁêÜËß£ `Callable` Âíå `Future` ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ

`FutureTask` Êèê‰æõ‰∫Ü `Future` Êé•Âè£ÁöÑÂü∫Êú¨ÂÆûÁé∞ÔºåÂ∏∏Áî®Êù•Â∞ÅË£Ö `Callable` Âíå `Runnable`ÔºåÂÖ∑ÊúâÂèñÊ∂à‰ªªÂä°„ÄÅÊü•Áúã‰ªªÂä°ÊòØÂê¶ÊâßË°åÂÆåÊàê‰ª•ÂèäËé∑Âèñ‰ªªÂä°ÊâßË°åÁªìÊûúÁöÑÊñπÊ≥ï„ÄÇ`ExecutorService.submit()` ÊñπÊ≥ïËøîÂõûÁöÑÂÖ∂ÂÆûÂ∞±ÊòØ `Future` ÁöÑÂÆûÁé∞Á±ª `FutureTask` „ÄÇ

```java
<T> Future<T> submit(Callable<T> task);
Future<?> submit(Runnable task);
```

`FutureTask` not only implements the `Future` interface, but also implements the `Runnable` interface, so it can be directly executed by a thread as a task.

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/completablefuture-class-diagram.jpg)

`FutureTask` has two constructors, which can pass in `Callable` or `Runnable` objects. In fact, passing in a `Runnable` object is also converted to a `Callable` object inside the method.

```java
public FutureTask(Callable<V> callable) {
    if (callable == null)
        throw new NullPointerException();
    this.callable = callable;
    this.state = NEW;
}
public FutureTask(Runnable runnable, V result) {
    // Convert the Runnable object runnable into a Callable object through the adapter RunnableAdapter
    this.callable = Executors.callable(runnable, result);
    this.state = NEW;
}
```

`FutureTask` is equivalent to encapsulating `Callable`, managing the task execution, and storing the task execution results of `Callable`'s `call` method.

For more source code details of `Future`, you can read this 10,000-word analysis, which is very clear: [How does Java implement the Future pattern? Detailed explanation of 10,000 words! ](https://juejin.cn/post/6844904199625375757).

### What is the use of the CompletableFuture class?

`Future` has some limitations in actual use. For example, it does not support the orchestration and combination of asynchronous tasks, and the `get()` method to obtain calculation results is a blocking call.

The `CompletableFuture` class was introduced in Java 8 to solve these shortcomings of `Future`. In addition to providing more easy-to-use and powerful `Future` features, `CompletableFuture` also provides functional programming, asynchronous task orchestration and combination (multiple asynchronous tasks can be connected in series to form a complete chain call) and other capabilities.

Let's take a brief look at the definition of the `CompletableFuture` class.

```java
public class CompletableFuture<T> implements Future<T>, CompletionStage<T> {
}
```

As you can see, `CompletableFuture` implements both the `Future` and `CompletionStage` interfaces.

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/completablefuture-class-diagram.jpg)

The `CompletionStage` interface describes an asynchronous computation stage. Many calculations can be divided into multiple stages or steps. At this time, it can be used to combine all steps to form an asynchronous calculation pipeline.

There are many methods in the `CompletionStage` interface, and the functional capabilities of `CompletableFuture` are given by this interface. From the method parameters of this interface, you can find that it makes extensive use of functional programming introduced in Java8.

![](https://oss.javaguide.cn/javaguide/image-20210902093026059.png)

### ‚≠êÔ∏èA task needs to depend on two other tasks before it is executed. How to design it?

This task orchestration scenario is very suitable to be implemented through `CompletableFuture`. It is assumed here that T3 is executed after T2 and T1 are executed.

The code is as follows (in order to simplify the code, Hutool‚Äôs thread tool class `ThreadUtil` and date and time tool class `DateUtil` are used):

```java
// T1
CompletableFuture<Void> futureT1 = CompletableFuture.runAsync(() -> {
    System.out.println("T1 is executing. Current time: " + DateUtil.now());
    // Simulate time-consuming operations
    ThreadUtil.sleep(1000);
});
//T2
CompletableFuture<Void> futureT2 = CompletableFuture.runAsync(() -> {
    System.out.println("T2 is executing. Current time: " + DateUtil.now());
    ThreadUtil.sleep(1000);
});

// Use the allOf() method to merge the CompletableFutures of T1 and T2 and wait for them to complete
CompletableFuture<Void> bothCompleted = CompletableFuture.allOf(futureT1, futureT2);
//When both T1 and T2 are completed, execute T3
bothCompleted.thenRunAsync(() -> System.out.println("T3 is executing after T1 and T2 have completed.Current time: " + DateUtil.now()));
// Wait for all tasks to be completed and verify the effect
ThreadUtil.sleep(3000);
```

Run T1 and T2 in parallel through the `allOf()` static method of `CompletableFuture`. When both T1 and T2 are completed, execute T3.

### ‚≠êÔ∏èUsing CompletableFuture, a task fails, how to handle the exception?

When using `CompletableFuture`, exceptions must be handled in the correct way to avoid exceptions being lost or uncontrollable problems.

Here are some suggestions:

- Use the `whenComplete` method to trigger the callback function when the task is completed and handle the exception correctly instead of letting the exception be swallowed or lost.
- Use the `exceptionally` method to handle exceptions and rethrow them so that they propagate to subsequent stages rather than having them ignored or terminated.
- Use the `handle` method to handle normal return results and exceptions, and return a new result instead of letting exceptions affect normal business logic.
- Use the `CompletableFuture.allOf` method to combine multiple `CompletableFuture` and handle exceptions for all tasks uniformly, instead of making exception handling too lengthy or repetitive.
-‚Ä¶

### ‚≠êÔ∏èWhy do you need to customize the thread pool when using CompletableFuture?

`CompletableFuture` uses the globally shared `ForkJoinPool.commonPool()` as the executor by default, and all asynchronous tasks that do not specify an executor will use this thread pool. This means that if an application, multiple libraries or frameworks (such as Spring, third-party libraries) all depend on `CompletableFuture`, they will all share the same thread pool by default.

Although `ForkJoinPool` is very efficient, when a large number of tasks are submitted at the same time, it may cause resource contention and thread starvation, thereby affecting system performance.

To avoid these problems, it is recommended to provide a custom thread pool for `CompletableFuture`, which brings the following advantages:

-Isolation: Allocate independent thread pools to different tasks to avoid global thread pool resource contention.
- Resource control: Adjust thread pool size and queue type according to task characteristics to optimize performance.
- Exception handling: Better handle exceptions in threads by customizing `ThreadFactory`.

```java
private ThreadPoolExecutor executor = new ThreadPoolExecutor(10, 10,
        0L, TimeUnit.MILLISECONDS,
        new LinkedBlockingQueue<Runnable>());

CompletableFuture.runAsync(() -> {
     //...
}, executor);
```

## AQS

For a detailed analysis of the AQS source code, you can read this article: [AQS Detailed Explanation](https://javaguide.cn/java/concurrent/aqs.html).

### What is AQS?

AQS (`AbstractQueuedSynchronizer`, abstract queue synchronizer) is a Java concurrency core component provided starting from JDK1.5.

AQS solves the complexity problem for developers when implementing synchronizers. It provides a general framework for implementing various synchronizers, such as ReentrantLock, Semaphore and CountDownLatch. By encapsulating the underlying thread synchronization mechanism, AQS hides complex thread management logic, allowing developers to only focus on specific synchronization logic.ÁÆÄÂçïÊù•ËØ¥ÔºåAQS ÊòØ‰∏Ä‰∏™ÊäΩË±°Á±ªÔºå‰∏∫ÂêåÊ≠•Âô®Êèê‰æõ‰∫ÜÈÄöÁî®ÁöÑ **ÊâßË°åÊ°ÜÊû∂**„ÄÇÂÆÉÂÆö‰πâ‰∫Ü **ËµÑÊ∫êËé∑ÂèñÂíåÈáäÊîæÁöÑÈÄöÁî®ÊµÅÁ®ã**ÔºåËÄåÂÖ∑‰ΩìÁöÑËµÑÊ∫êËé∑ÂèñÈÄªËæëÂàôÁî±ÂÖ∑‰ΩìÂêåÊ≠•Âô®ÈÄöËøáÈáçÂÜôÊ®°ÊùøÊñπÊ≥ïÊù•ÂÆûÁé∞„ÄÇ Âõ†Ê≠§ÔºåÂèØ‰ª•Â∞Ü AQS Áúã‰ΩúÊòØÂêåÊ≠•Âô®ÁöÑ **Âü∫Á°Ä‚ÄúÂ∫ïÂ∫ß‚Äù**ÔºåËÄåÂêåÊ≠•Âô®ÂàôÊòØÂü∫‰∫é AQS ÂÆûÁé∞ÁöÑ **ÂÖ∑‰Ωì‚ÄúÂ∫îÁî®‚Äù**„ÄÇ

### ‚≠êÔ∏èAQS ÁöÑÂéüÁêÜÊòØ‰ªÄ‰πàÔºü

AQS Ê†∏ÂøÉÊÄùÊÉ≥ÊòØÔºåÂ¶ÇÊûúË¢´ËØ∑Ê±ÇÁöÑÂÖ±‰∫´ËµÑÊ∫êÁ©∫Èó≤ÔºåÂàôÂ∞ÜÂΩìÂâçËØ∑Ê±ÇËµÑÊ∫êÁöÑÁ∫øÁ®ãËÆæÁΩÆ‰∏∫ÊúâÊïàÁöÑÂ∑•‰ΩúÁ∫øÁ®ãÔºåÂπ∂‰∏îÂ∞ÜÂÖ±‰∫´ËµÑÊ∫êËÆæÁΩÆ‰∏∫ÈîÅÂÆöÁä∂ÊÄÅ„ÄÇÂ¶ÇÊûúË¢´ËØ∑Ê±ÇÁöÑÂÖ±‰∫´ËµÑÊ∫êË¢´Âç†Áî®ÔºåÈÇ£‰πàÂ∞±ÈúÄË¶Å‰∏ÄÂ•óÁ∫øÁ®ãÈòªÂ°ûÁ≠âÂæÖ‰ª•ÂèäË¢´Âî§ÈÜíÊó∂ÈîÅÂàÜÈÖçÁöÑÊú∫Âà∂ÔºåËøô‰∏™Êú∫Âà∂ AQS ÊòØÂü∫‰∫é **CLH ÈîÅ** ÔºàCraig, Landin, and Hagersten locksÔºâ Ëøõ‰∏ÄÊ≠•‰ºòÂåñÂÆûÁé∞ÁöÑ„ÄÇ

**CLH ÈîÅ** ÂØπËá™ÊóãÈîÅËøõË°å‰∫ÜÊîπËøõÔºåÊòØÂü∫‰∫éÂçïÈìæË°®ÁöÑËá™ÊóãÈîÅ„ÄÇÂú®Â§öÁ∫øÁ®ãÂú∫ÊôØ‰∏ãÔºå‰ºöÂ∞ÜËØ∑Ê±ÇËé∑ÂèñÈîÅÁöÑÁ∫øÁ®ãÁªÑÁªáÊàê‰∏Ä‰∏™ÂçïÂêëÈòüÂàóÔºåÊØè‰∏™Á≠âÂæÖÁöÑÁ∫øÁ®ã‰ºöÈÄöËøáËá™ÊóãËÆøÈóÆÂâç‰∏Ä‰∏™Á∫øÁ®ãËäÇÁÇπÁöÑÁä∂ÊÄÅÔºåÂâç‰∏Ä‰∏™ËäÇÁÇπÈáäÊîæÈîÅ‰πãÂêéÔºåÂΩìÂâçËäÇÁÇπÊâçÂèØ‰ª•Ëé∑ÂèñÈîÅ„ÄÇ**CLH ÈîÅ** ÁöÑÈòüÂàóÁªìÊûÑÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ

![CLH ÈîÅÁöÑÈòüÂàóÁªìÊûÑ](https://oss.javaguide.cn/github/javaguide/open-source-project/clh-lock-queue-structure.png)

AQS ‰∏≠‰ΩøÁî®ÁöÑ **Á≠âÂæÖÈòüÂàó** ÊòØ CLH ÈîÅÈòüÂàóÁöÑÂèò‰ΩìÔºàÊé•‰∏ãÊù•ÁÆÄÁß∞‰∏∫ CLH Âèò‰ΩìÈòüÂàóÔºâ„ÄÇ

AQS ÁöÑ CLH Âèò‰ΩìÈòüÂàóÊòØ‰∏Ä‰∏™ÂèåÂêëÈòüÂàóÔºå‰ºöÊöÇÊó∂Ëé∑Âèñ‰∏çÂà∞ÈîÅÁöÑÁ∫øÁ®ãÂ∞ÜË¢´Âä†ÂÖ•Âà∞ËØ•ÈòüÂàó‰∏≠ÔºåCLH Âèò‰ΩìÈòüÂàóÂíåÂéüÊú¨ÁöÑ CLH ÈîÅÈòüÂàóÁöÑÂå∫Âà´‰∏ªË¶ÅÊúâ‰∏§ÁÇπÔºö

- Áî± **Ëá™Êóã** ‰ºòÂåñ‰∏∫ **Ëá™Êóã + ÈòªÂ°û** ÔºöËá™ÊóãÊìç‰ΩúÁöÑÊÄßËÉΩÂæàÈ´òÔºå‰ΩÜÂ§ßÈáèÁöÑËá™ÊóãÊìç‰ΩúÊØîËæÉÂç†Áî® CPU ËµÑÊ∫êÔºåÂõ†Ê≠§Âú® CLH Âèò‰ΩìÈòüÂàó‰∏≠‰ºöÂÖàÈÄöËøáËá™ÊóãÂ∞ùËØïËé∑ÂèñÈîÅÔºåÂ¶ÇÊûúÂ§±Ë¥•ÂÜçËøõË°åÈòªÂ°ûÁ≠âÂæÖ„ÄÇ
- Áî± **ÂçïÂêëÈòüÂàó** ‰ºòÂåñ‰∏∫ **ÂèåÂêëÈòüÂàó** ÔºöÂú® CLH Âèò‰ΩìÈòüÂàó‰∏≠Ôºå‰ºöÂØπÁ≠âÂæÖÁöÑÁ∫øÁ®ãËøõË°åÈòªÂ°ûÊìç‰ΩúÔºåÂΩìÈòüÂàóÂâçËæπÁöÑÁ∫øÁ®ãÈáäÊîæÈîÅ‰πãÂêéÔºåÈúÄË¶ÅÂØπÂêéËæπÁöÑÁ∫øÁ®ãËøõË°åÂî§ÈÜíÔºåÂõ†Ê≠§Â¢ûÂä†‰∫Ü `next` ÊåáÈíàÔºåÊàê‰∏∫‰∫ÜÂèåÂêëÈòüÂàó„ÄÇ

AQS Â∞ÜÊØèÊù°ËØ∑Ê±ÇÂÖ±‰∫´ËµÑÊ∫êÁöÑÁ∫øÁ®ãÂ∞ÅË£ÖÊàê‰∏Ä‰∏™ CLH Âèò‰ΩìÈòüÂàóÁöÑ‰∏Ä‰∏™ÁªìÁÇπÔºàNodeÔºâÊù•ÂÆûÁé∞ÈîÅÁöÑÂàÜÈÖç„ÄÇÂú® CLH Âèò‰ΩìÈòüÂàó‰∏≠Ôºå‰∏Ä‰∏™ËäÇÁÇπË°®Á§∫‰∏Ä‰∏™Á∫øÁ®ãÔºåÂÆÉ‰øùÂ≠òÁùÄÁ∫øÁ®ãÁöÑÂºïÁî®ÔºàthreadÔºâ„ÄÅ ÂΩìÂâçËäÇÁÇπÂú®ÈòüÂàó‰∏≠ÁöÑÁä∂ÊÄÅÔºàwaitStatusÔºâ„ÄÅÂâçÈ©±ËäÇÁÇπÔºàprevÔºâ„ÄÅÂêéÁªßËäÇÁÇπÔºànextÔºâ„ÄÇ

AQS ‰∏≠ÁöÑ CLH Âèò‰ΩìÈòüÂàóÁªìÊûÑÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![CLH Âèò‰ΩìÈòüÂàóÁªìÊûÑ](https://oss.javaguide.cn/github/javaguide/java/concurrent/clh-queue-structure-bianti.png)

AQS(`AbstractQueuedSynchronizer`)ÁöÑÊ†∏ÂøÉÂéüÁêÜÂõæÔºö

![CLH Âèò‰ΩìÈòüÂàó](https://oss.javaguide.cn/github/javaguide/java/concurrent/clh-queue-state.png)

AQS ‰ΩøÁî® **int ÊàêÂëòÂèòÈáè `state` Ë°®Á§∫ÂêåÊ≠•Áä∂ÊÄÅ**ÔºåÈÄöËøáÂÜÖÁΩÆÁöÑ **Á∫øÁ®ãÁ≠âÂæÖÈòüÂàó** Êù•ÂÆåÊàêËé∑ÂèñËµÑÊ∫êÁ∫øÁ®ãÁöÑÊéíÈòüÂ∑•‰Ωú„ÄÇ

`state` ÂèòÈáèÁî± `volatile` ‰øÆÈ•∞ÔºåÁî®‰∫éÂ±ïÁ§∫ÂΩìÂâç‰∏¥ÁïåËµÑÊ∫êÁöÑËé∑ÈîÅÊÉÖÂÜµ„ÄÇ

```java
// ÂÖ±‰∫´ÂèòÈáèÔºå‰ΩøÁî®volatile‰øÆÈ•∞‰øùËØÅÁ∫øÁ®ãÂèØËßÅÊÄß
private volatile int state;
```

Âè¶Â§ñÔºåÁä∂ÊÄÅ‰ø°ÊÅØ `state` ÂèØ‰ª•ÈÄöËøá `protected` Á±ªÂûãÁöÑ`getState()`„ÄÅ`setState()`Âíå`compareAndSetState()` ËøõË°åÊìç‰Ωú„ÄÇÂπ∂‰∏îÔºåËøôÂá†‰∏™ÊñπÊ≥ïÈÉΩÊòØ `final` ‰øÆÈ•∞ÁöÑÔºåÂú®Â≠êÁ±ª‰∏≠Êó†Ê≥ïË¢´ÈáçÂÜô„ÄÇ

```java
//ËøîÂõûÂêåÊ≠•Áä∂ÊÄÅÁöÑÂΩìÂâçÂÄº
protected final int getState() {
     return state;
}
 // ËÆæÁΩÆÂêåÊ≠•Áä∂ÊÄÅÁöÑÂÄº
protected final void setState(int newState) {
     state = newState;
}
//ÂéüÂ≠êÂú∞ÔºàCASÊìç‰ΩúÔºâÂ∞ÜÂêåÊ≠•Áä∂ÊÄÅÂÄºËÆæÁΩÆ‰∏∫ÁªôÂÆöÂÄºupdateÂ¶ÇÊûúÂΩìÂâçÂêåÊ≠•Áä∂ÊÄÅÁöÑÂÄºÁ≠â‰∫éexpectÔºàÊúüÊúõÂÄºÔºâ
protected final boolean compareAndSetState(int expect, int update) {
      return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```

‰ª• `ReentrantLock` ‰∏∫‰æãÔºå`state` ÂàùÂßãÂÄº‰∏∫ 0ÔºåË°®Á§∫Êú™ÈîÅÂÆöÁä∂ÊÄÅ„ÄÇA Á∫øÁ®ã `lock()` Êó∂Ôºå‰ºöË∞ÉÁî® `tryAcquire()` Áã¨Âç†ËØ•ÈîÅÂπ∂Â∞Ü `state+1` „ÄÇÊ≠§ÂêéÔºåÂÖ∂‰ªñÁ∫øÁ®ãÂÜç `tryAcquire()` Êó∂Â∞±‰ºöÂ§±Ë¥•ÔºåÁõ¥Âà∞ A Á∫øÁ®ã `unlock()` Âà∞ `state=`0ÔºàÂç≥ÈáäÊîæÈîÅÔºâ‰∏∫Ê≠¢ÔºåÂÖ∂ÂÆÉÁ∫øÁ®ãÊâçÊúâÊú∫‰ºöËé∑ÂèñËØ•ÈîÅ„ÄÇÂΩìÁÑ∂ÔºåÈáäÊîæÈîÅ‰πãÂâçÔºåA Á∫øÁ®ãËá™Â∑±ÊòØÂèØ‰ª•ÈáçÂ§çËé∑ÂèñÊ≠§ÈîÅÁöÑÔºà`state` ‰ºöÁ¥ØÂä†ÔºâÔºåËøôÂ∞±ÊòØÂèØÈáçÂÖ•ÁöÑÊ¶ÇÂøµ„ÄÇ‰ΩÜË¶ÅÊ≥®ÊÑèÔºåËé∑ÂèñÂ§öÂ∞ëÊ¨°Â∞±Ë¶ÅÈáäÊîæÂ§öÂ∞ëÊ¨°ÔºåËøôÊ†∑ÊâçËÉΩ‰øùËØÅ state ÊòØËÉΩÂõûÂà∞Èõ∂ÊÄÅÁöÑ„ÄÇ

ÂÜç‰ª• `CountDownLatch` ‰ª•‰æãÔºå‰ªªÂä°ÂàÜ‰∏∫ N ‰∏™Â≠êÁ∫øÁ®ãÂéªÊâßË°åÔºå`state` ‰πüÂàùÂßãÂåñ‰∏∫ NÔºàÊ≥®ÊÑè N Ë¶Å‰∏éÁ∫øÁ®ã‰∏™Êï∞‰∏ÄËá¥Ôºâ„ÄÇËøô N ‰∏™Â≠êÁ∫øÁ®ãÊòØÂπ∂Ë°åÊâßË°åÁöÑÔºåÊØè‰∏™Â≠êÁ∫øÁ®ãÊâßË°åÂÆåÂêé`countDown()` ‰∏ÄÊ¨°Ôºåstate ‰ºö CAS(Compare and Swap) Âáè 1„ÄÇÁ≠âÂà∞ÊâÄÊúâÂ≠êÁ∫øÁ®ãÈÉΩÊâßË°åÂÆåÂêé(Âç≥ `state=0` )Ôºå‰ºö `unpark()` ‰∏ªË∞ÉÁî®Á∫øÁ®ãÔºåÁÑ∂Âêé‰∏ªË∞ÉÁî®Á∫øÁ®ãÂ∞±‰ºö‰ªé `await()` ÂáΩÊï∞ËøîÂõûÔºåÁªßÁª≠ÂêéÁª≠Âä®‰Ωú„ÄÇ

### Semaphore Êúâ‰ªÄ‰πàÁî®Ôºü

`synchronized` Âíå `ReentrantLock` ÈÉΩÊòØ‰∏ÄÊ¨°Âè™ÂÖÅËÆ∏‰∏Ä‰∏™Á∫øÁ®ãËÆøÈóÆÊüê‰∏™ËµÑÊ∫êÔºåËÄå`Semaphore`(‰ø°Âè∑Èáè)ÂèØ‰ª•Áî®Êù•ÊéßÂà∂ÂêåÊó∂ËÆøÈóÆÁâπÂÆöËµÑÊ∫êÁöÑÁ∫øÁ®ãÊï∞Èáè„ÄÇ

Semaphore ÁöÑ‰ΩøÁî®ÁÆÄÂçïÔºåÊàë‰ª¨ËøôÈáåÂÅáËÆæÊúâ N(N>5) ‰∏™Á∫øÁ®ãÊù•Ëé∑Âèñ `Semaphore` ‰∏≠ÁöÑÂÖ±‰∫´ËµÑÊ∫êÔºå‰∏ãÈù¢ÁöÑ‰ª£Á†ÅË°®Á§∫Âêå‰∏ÄÊó∂Âàª N ‰∏™Á∫øÁ®ã‰∏≠Âè™Êúâ 5 ‰∏™Á∫øÁ®ãËÉΩËé∑ÂèñÂà∞ÂÖ±‰∫´ËµÑÊ∫êÔºåÂÖ∂‰ªñÁ∫øÁ®ãÈÉΩ‰ºöÈòªÂ°ûÔºåÂè™ÊúâËé∑ÂèñÂà∞ÂÖ±‰∫´ËµÑÊ∫êÁöÑÁ∫øÁ®ãÊâçËÉΩÊâßË°å„ÄÇÁ≠âÂà∞ÊúâÁ∫øÁ®ãÈáäÊîæ‰∫ÜÂÖ±‰∫´ËµÑÊ∫êÔºåÂÖ∂‰ªñÈòªÂ°ûÁöÑÁ∫øÁ®ãÊâçËÉΩËé∑ÂèñÂà∞„ÄÇ

```java
// ÂàùÂßãÂÖ±‰∫´ËµÑÊ∫êÊï∞Èáè
final Semaphore semaphore = new Semaphore(5);
// Ëé∑Âèñ1‰∏™ËÆ∏ÂèØ
semaphore.acquire();
// ÈáäÊîæ1‰∏™ËÆ∏ÂèØ
semaphore.release();
```

ÂΩìÂàùÂßãÁöÑËµÑÊ∫ê‰∏™Êï∞‰∏∫ 1 ÁöÑÊó∂ÂÄôÔºå`Semaphore` ÈÄÄÂåñ‰∏∫Êéí‰ªñÈîÅ„ÄÇ

`Semaphore` Êúâ‰∏§ÁßçÊ®°ÂºèÔºö„ÄÇ

- **ÂÖ¨Âπ≥Ê®°ÂºèÔºö** Ë∞ÉÁî® `acquire()` ÊñπÊ≥ïÁöÑÈ°∫Â∫èÂ∞±ÊòØËé∑ÂèñËÆ∏ÂèØËØÅÁöÑÈ°∫Â∫èÔºåÈÅµÂæ™ FIFOÔºõ
- **ÈùûÂÖ¨Âπ≥Ê®°ÂºèÔºö** Êä¢Âç†ÂºèÁöÑ„ÄÇ

`Semaphore` ÂØπÂ∫îÁöÑ‰∏§‰∏™ÊûÑÈÄ†ÊñπÊ≥ïÂ¶Ç‰∏ãÔºö

```java
public Semaphore(int permits) {
    sync = new NonfairSync(permits);
}

public Semaphore(int permits, boolean fair) {
    sync = fair ? new FairSync(permits) : new NonfairSync(permits);
}
```

**Ëøô‰∏§‰∏™ÊûÑÈÄ†ÊñπÊ≥ïÔºåÈÉΩÂøÖÈ°ªÊèê‰æõËÆ∏ÂèØÁöÑÊï∞ÈáèÔºåÁ¨¨‰∫å‰∏™ÊûÑÈÄ†ÊñπÊ≥ïÂèØ‰ª•ÊåáÂÆöÊòØÂÖ¨Âπ≥Ê®°ÂºèËøòÊòØÈùûÂÖ¨Âπ≥Ê®°ÂºèÔºåÈªòËÆ§ÈùûÂÖ¨Âπ≥Ê®°Âºè„ÄÇ**

`Semaphore` ÈÄöÂ∏∏Áî®‰∫éÈÇ£‰∫õËµÑÊ∫êÊúâÊòéÁ°ÆËÆøÈóÆÊï∞ÈáèÈôêÂà∂ÁöÑÂú∫ÊôØÊØîÂ¶ÇÈôêÊµÅÔºà‰ªÖÈôê‰∫éÂçïÊú∫Ê®°ÂºèÔºåÂÆûÈôÖÈ°πÁõÆ‰∏≠Êé®Ëçê‰ΩøÁî® Redis +Lua Êù•ÂÅöÈôêÊµÅÔºâ„ÄÇ

### Semaphore ÁöÑÂéüÁêÜÊòØ‰ªÄ‰πàÔºü

`Semaphore` ÊòØÂÖ±‰∫´ÈîÅÁöÑ‰∏ÄÁßçÂÆûÁé∞ÔºåÂÆÉÈªòËÆ§ÊûÑÈÄ† AQS ÁöÑ `state` ÂÄº‰∏∫ `permits`Ôºå‰Ω†ÂèØ‰ª•Â∞Ü `permits` ÁöÑÂÄºÁêÜËß£‰∏∫ËÆ∏ÂèØËØÅÁöÑÊï∞ÈáèÔºåÂè™ÊúâÊãøÂà∞ËÆ∏ÂèØËØÅÁöÑÁ∫øÁ®ãÊâçËÉΩÊâßË°å„ÄÇ

Ë∞ÉÁî®`semaphore.acquire()` ÔºåÁ∫øÁ®ãÂ∞ùËØïËé∑ÂèñËÆ∏ÂèØËØÅÔºåÂ¶ÇÊûú `state >= 0` ÁöÑËØùÔºåÂàôË°®Á§∫ÂèØ‰ª•Ëé∑ÂèñÊàêÂäü„ÄÇÂ¶ÇÊûúËé∑ÂèñÊàêÂäüÁöÑËØùÔºå‰ΩøÁî® CAS Êìç‰ΩúÂéª‰øÆÊîπ `state` ÁöÑÂÄº `state=state-1`„ÄÇÂ¶ÇÊûú `state<0` ÁöÑËØùÔºåÂàôË°®Á§∫ËÆ∏ÂèØËØÅÊï∞Èáè‰∏çË∂≥„ÄÇÊ≠§Êó∂‰ºöÂàõÂª∫‰∏Ä‰∏™ Node ËäÇÁÇπÂä†ÂÖ•ÈòªÂ°ûÈòüÂàóÔºåÊåÇËµ∑ÂΩìÂâçÁ∫øÁ®ã„ÄÇ

```java
/**
 *  Ëé∑Âèñ1‰∏™ËÆ∏ÂèØËØÅ
 */
public void acquire() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}
/**
 * ÂÖ±‰∫´Ê®°Âºè‰∏ãËé∑ÂèñËÆ∏ÂèØËØÅÔºåËé∑ÂèñÊàêÂäüÂàôËøîÂõûÔºåÂ§±Ë¥•ÂàôÂä†ÂÖ•ÈòªÂ°ûÈòüÂàóÔºåÊåÇËµ∑Á∫øÁ®ã
 */
public final void acquireSharedInterruptibly(int arg)
    throws InterruptedException {
    if (Thread.interrupted())
      throw new InterruptedException();
        // Â∞ùËØïËé∑ÂèñËÆ∏ÂèØËØÅÔºåarg‰∏∫Ëé∑ÂèñËÆ∏ÂèØËØÅ‰∏™Êï∞ÔºåÂΩìÂèØÁî®ËÆ∏ÂèØËØÅÊï∞ÂáèÂΩìÂâçËé∑ÂèñÁöÑËÆ∏ÂèØËØÅÊï∞ÁªìÊûúÂ∞è‰∫é0,ÂàôÂàõÂª∫‰∏Ä‰∏™ËäÇÁÇπÂä†ÂÖ•ÈòªÂ°ûÈòüÂàóÔºåÊåÇËµ∑ÂΩìÂâçÁ∫øÁ®ã„ÄÇ
    if (tryAcquireShared(arg) < 0)
      doAcquireSharedInterruptibly(arg);
}
```

Calling `semaphore.release();`, the thread attempts to release the license and uses the CAS operation to modify the value of `state` to `state=state+1`. After the license is released successfully, a thread in the synchronization queue will be awakened at the same time. The awakened thread will retry to modify the value of `state` to `state=state-1`. If `state>=0`, the token is obtained successfully, otherwise it will re-enter the blocking queue and suspend the thread.

```java
// Release a license
public void release() {
    sync.releaseShared(1);
}

// Release the shared lock and wake up a thread in the synchronization queue.
public final boolean releaseShared(int arg) {
    //Release shared lock
    if (tryReleaseShared(arg)) {
      //Wake up a thread in the synchronization queue
      doReleaseShared();
      return true;
    }
    return false;
}
```

### What is the use of CountDownLatch?

`CountDownLatch` allows `count` threads to block in one place until all threads' tasks are completed.

`CountDownLatch` is one-time use. The value of the counter can only be initialized once in the constructor. There is no mechanism to set its value again afterwards. When `CountDownLatch` is used, it cannot be used again.

### What is the principle of CountDownLatch?

`CountDownLatch` is an implementation of shared locks. It constructs the `state` value of AQS by default as `count`. When the thread uses the `countDown()` method, it actually uses the `tryReleaseShared` method to reduce `state` with CAS operations until `state` is 0. When calling the `await()` method, if `state` is not 0, it proves that the task has not been completed, and the `await()` method will always block, which means that the statements after the `await()` method will not be executed. Until `count` threads call `countDown()` so that the state value is reduced to 0, or the thread calling `await()` is interrupted, the thread will be awakened from blocking, and the statements after the `await()` method will be executed.

### Have you ever used CountDownLatch? In what scenario is it used?

The function of `CountDownLatch` is to allow count threads to block in one place until all threads' tasks are completed. In the previous project, there was a scenario where multi-threading was used to read and process multiple files. I used `CountDownLatch`. The specific scenario is as follows:

We need to read and process 6 files. These 6 tasks are all tasks that have no execution order dependency, but we need to statistically organize the results of processing these files when returning them to the user.

For this we define a thread pool and a `CountDownLatch` object with a count of 6. Use the thread pool to handle the reading task. After each thread is processed, it will count-1 and call the `await()` method of the `CountDownLatch` object. The subsequent logic will not be executed until all files have been read.

The pseudocode is as follows:

```java
public class CountDownLatchExample1 {
    //Number of files to process
    private static final int threadCount = 6;

    public static void main(String[] args) throws InterruptedException {
        // Create a thread pool object with a fixed number of threads (it is recommended to use the constructor method to create it)
        ExecutorService threadPool = Executors.newFixedThreadPool(10);
        final CountDownLatch countDownLatch = new CountDownLatch(threadCount);
        for (int i = 0; i < threadCount; i++) {
            final int threadnum = i;
            threadPool.execute(() -> {
                try {
                    //Business operations for processing files
                    //......
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    //Indicates that a file has been completed
                    countDownLatch.countDown();
                }

            });
        }
        countDownLatch.await();
        threadPool.shutdown();
        System.out.println("finish");
    }
}
```

**Is there anything that can be improved? **

This can be improved using the `CompletableFuture` class! Java8's `CompletableFuture` provides many multi-thread-friendly methods. It can be used to easily write multi-threaded programs for us. It is very convenient to be asynchronous, serial, parallel or wait for all threads to finish executing tasks.

```java
CompletableFuture<Void> task1 =
    CompletableFuture.supplyAsync(()->{
        //Customized business operations
    });
...
CompletableFuture<Void> task6 =
    CompletableFuture.supplyAsync(()->{
    //Customized business operations
    });
...
CompletableFuture<Void> headerFuture=CompletableFuture.allOf(task1,....,task6);

try {
    headerFuture.join();
} catch (Exception ex) {
    //......
}
System.out.println("all done. ");
```

The above code can continue to be optimized. When there are too many tasks, it is not practical to list every task. You can consider adding tasks through a loop.

```java
//Folder location
List<String> filePaths = Arrays.asList(...)
// Process all files asynchronously
List<CompletableFuture<String>> fileFutures = filePaths.stream()
    .map(filePath -> doSomeThing(filePath))
    .collect(Collectors.toList());
// merge them
CompletableFuture<Void> allFutures = CompletableFuture.allOf(
    fileFutures.toArray(new CompletableFuture[fileFutures.size()])
);
```

### What is the use of CyclicBarrier?

`CyclicBarrier` is very similar to `CountDownLatch`. It can also implement technical waiting between threads, but its function is more complex and powerful than `CountDownLatch`. The main application scenarios are similar to `CountDownLatch`.

> The implementation of `CountDownLatch` is based on AQS, while `CyclicBarrier` is based on `ReentrantLock` (`ReentrantLock` also belongs to the AQS synchronizer) and `Condition`.

`CyclicBarrier` literally means cyclic barrier. What it does is: let a group of threads be blocked when they reach a barrier (also called a synchronization point). The barrier will not open until the last thread reaches the barrier, and all threads intercepted by the barrier will continue to work.

### What is the principle of CyclicBarrier?

`CyclicBarrier` internally uses a `count` variable as a counter. The initial value of `count` is the initialization value of the `parties` attribute. Whenever a thread reaches the barrier, the counter is decremented by 1. If the count value is 0, it means that this is the last thread of this generation to reach the fence, and it will try to execute the task entered in our constructor.

```java
//The number of threads intercepted each time
private final int parties;
//Counter
private int count;
```

Let‚Äôs take a brief look at the source code below.1. The default constructor of `CyclicBarrier` is `CyclicBarrier(int parties)`, whose parameters represent the number of threads intercepted by the barrier. Each thread calls the `await()` method to tell `CyclicBarrier` that I have reached the barrier, and then the current thread is blocked.

```java
public CyclicBarrier(int parties) {
    this(parties, null);
}

public CyclicBarrier(int parties, Runnable barrierAction) {
    if (parties <= 0) throw new IllegalArgumentException();
    this.parties = parties;
    this.count = parties;
    this.barrierCommand = barrierAction;
}
```

Among them, `parties` represents the number of intercepted threads. When the number of intercepted threads reaches this value, the fence will be opened to allow all threads to pass.

2. When calling the `await()` method of the `CyclicBarrier` object, the `dowait(false, 0L)` method is actually called. The `await()` method acts like erecting a fence, blocking threads. When the number of blocked threads reaches the value of `parties`, the fence will open and the threads can pass for execution.

```java
public int await() throws InterruptedException, BrokenBarrierException {
  try {
      return dowait(false, 0L);
  } catch (TimeoutException toe) {
      throw new Error(toe); // cannot happen
  }
}
```

The source code analysis of `dowait(false, 0L)` method is as follows:

```java
    // When the number of threads or the number of requests reaches count, the method after await will be executed. In the above example, the value of count is 5.
    private int count;
    /**
     * Main barrier code, covering the various policies.
     */
    private int dowait(boolean timed, long nanos)
        throws InterruptedException, BrokenBarrierException,
               TimeoutException {
        final ReentrantLock lock = this.lock;
        // lock
        lock.lock();
        try {
            final Generation g = generation;

            if (g.broken)
                throw new BrokenBarrierException();

            //If the thread is interrupted, throw an exception
            if (Thread.interrupted()) {
                breakBarrier();
                throw new InterruptedException();
            }
            // cout decreases by 1
            int index = --count;
            // When the count is reduced to 0, it means that the last thread has reached the fence, that is, it has reached the condition after which the await method can be executed.
            if (index == 0) { // tripped
                boolean ranAction = false;
                try {
                    final Runnable command = barrierCommand;
                    if (command != null)
                        command.run();
                    ranAction = true;
                    //Reset count to the initialization value of the parties property
                    // Wake up the previously waiting thread
                    //The next wave of execution begins
                    nextGeneration();
                    return 0;
                } finally {
                    if (!ranAction)
                        breakBarrier();
                }
            }

            // loop until tripped, broken, interrupted, or timed out
            for (;;) {
                try {
                    if (!timed)
                        trip.await();
                    else if (nanos > 0L)
                        nanos = trip.awaitNanos(nanos);
                } catch (InterruptedException ie) {
                    if (g == generation && ! g.broken) {
                        breakBarrier();
                        throw ie;
                    } else {
                        // We're about to finish waiting even if we had not
                        // been interrupted, so this interrupt is deemed to
                        // "belong" to subsequent execution.
                        Thread.currentThread().interrupt();
                    }
                }

                if (g.broken)
                    throw new BrokenBarrierException();

                if (g != generation)
                    return index;

                if (timed && nanos <= 0L) {
                    breakBarrier();
                    throw new TimeoutException();
                }
            }
        } finally {
            lock.unlock();
        }
    }
```

## Virtual thread

Virtual threads were officially released in Java 21, which is a major update. Although there are not many questions asked in interviews at present, it is still recommended that everyone take a brief look. I wrote an article to summarize common problems with virtual threads: [Summary of common problems with virtual threads](https://javaguide.cn/java/concurrent/virtual-thread.html), including the following questions:

1. What is a virtual thread?
2. What is the relationship between virtual threads and platform threads?
3. What are the advantages and disadvantages of virtual threads?
4. How to create a virtual thread?
5. What is the underlying principle of virtual threads?

## Reference

- "In-depth Understanding of Java Virtual Machine"
- "Practical Java High Concurrency Programming"
- The implementation principle of Java thread pool and its best practices in business: Alibaba Cloud Developer: <https://mp.weixin.qq.com/s/icrrxEsbABBvEU0Gym7D5Q>
- Let you know about SynchronousQueue (concurrent queue topic): <https://juejin.cn/post/7031196740128768037>- Blocking queue ‚Äî DelayedWorkQueue source code analysis: <https://zhuanlan.zhihu.com/p/310621485>
- Java multi-threading (3) - FutureTask/CompletableFuture: <https://www.cnblogs.com/iwehdio/p/14285282.html>
- Detailed explanation of Java concurrency AQS: <https://www.cnblogs.com/waterystone/p/4920797.html>
- Cornerstone of Java concurrency package-AQS detailed explanation: <https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html>

<!-- @include: @article-footer.snippet.md -->